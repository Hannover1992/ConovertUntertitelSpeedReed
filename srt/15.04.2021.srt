1
00:00:00,000 --> 00:00:06,500
So, jetzt wird hier aufgezeichnet für das Video nochmal. Herzlich Willkommen zur digitalen Bildverarbeitung.

2
00:00:06,500 --> 00:00:15,000
Bei den Videos, die wir dann später veröffentlichen, wird das, was Sie im Chat schreiben oder das, was Sie sagen, nicht auftauchen.

3
00:00:15,000 --> 00:00:23,000
Also von daher können Sie ruhig in der Vorlesung etwas sagen, Fragen stellen.

4
00:00:23,000 --> 00:00:27,000
Sie müssen keine Angst haben, dass das für die Nachwelt erhalten bleibt.

5
00:00:30,000 --> 00:00:38,000
Und ja, Sie können Labor und Klausur bestehen, wann immer Sie wollen.

6
00:00:38,000 --> 00:00:44,000
Also immer nur zu angebotenen Terminen, aber das eine in diesem Jahr und das nächste in fünf Jahren oder ungefähr, passt.

7
00:00:44,000 --> 00:00:46,000
Gut.

8
00:00:46,000 --> 00:00:55,000
Am Anfang werde ich Ihnen ein paar Anwendungsbeispiele der digitalen Bildverarbeitung zeigen.

9
00:00:55,000 --> 00:01:04,000
Das Ganze ist jetzt etwas weniger mit Videos untermalt, weil wir es hier jetzt online machen müssen.

10
00:01:04,000 --> 00:01:09,000
Begriff digitale Bildverarbeitung. Jeder hat so gleich seine Vorstellung.

11
00:01:09,000 --> 00:01:15,000
Ich versuche das ein bisschen abzugrenzen, was ist ein Bildverarbeitungssystem und was soll es dann in dieser Lehrveranstaltung geben.

12
00:01:15,000 --> 00:01:18,000
Das wird sicherlich als erstes kommen.

13
00:01:18,000 --> 00:01:26,000
Und dann, wenn wir über Bilder sprechen, dann sprechen wir eigentlich in erster Linie erstmal über den Menschen.

14
00:01:26,000 --> 00:01:41,000
Das heißt, es gibt ein paar Worte zum menschlichen visuellen System und dann aber auch zu den Sensoren, die das digitalen Bild verarbeiten.

15
00:01:41,000 --> 00:01:45,000
Es gibt den Begriff der digitalen Bildverarbeitung.

16
00:01:45,000 --> 00:02:00,000
Auch Name der Vorlesung. Viel Technik ist im Englischen unterwegs. Im Englischen heißt es Digital Image Processing.

17
00:02:00,000 --> 00:02:08,000
Der Begriff Computer Vision ist eigentlich ein Begriff, der sehr verbreitet im Deutschen ist, zumindest in der Technik.

18
00:02:08,000 --> 00:02:15,000
Das ist ein englischer Begriff. Der deutsche Begriff Computersehen ist eher nicht so verbreitet.

19
00:02:15,000 --> 00:02:23,000
Maschinensehen, maschinelles Sehen heißt dann im Englischen Machine Vision, Computer Vision, Machine Vision.

20
00:02:23,000 --> 00:02:33,000
Der Unterschied ist mir nicht immer unbedingt klar, denn wenn man über Machine Vision spricht, dann ist die Auswertung der Bilder sicherlich immer Aufgabe eines Computers.

21
00:02:33,000 --> 00:02:44,000
Und dann sind wir schon dabei, dass Computer Vision und Machine Vision nicht scharf voneinander zu trennen sind.

22
00:02:44,000 --> 00:02:51,000
Was sind so Beispiele? Das, was man bei der Bildverarbeitung macht.

23
00:02:51,000 --> 00:03:00,000
Was sehen Sie hier? Ein Beispiel. Verbesserung eines Farbfotos.

24
00:03:00,000 --> 00:03:08,000
Unter Original können wir verstehen letztendlich das Bild, was Ihnen der Sensor liefert.

25
00:03:08,000 --> 00:03:22,000
Wenn Sie eine professionelle Videokamera haben, die Bilder im RAW-Format abspeichert, dann könnten Sie sagen, Sie schauen sich die Bilder einmal an, das ist das, was der Sensor liefert.

26
00:03:22,000 --> 00:03:32,000
Nicht unbedingt ein schönes Bild. Und dann kommt die Magie Ihres Fotoapparates oder auch Ihres Handys und raus kommt dann ein Bild, was deutlich besser aussieht.

27
00:03:32,000 --> 00:03:37,000
Die Farben sind da, die Helligkeiten passen so, dass Sie auch irgendwie was erkennen können.

28
00:03:37,000 --> 00:03:46,000
Das ist ein Beispiel von der Verarbeitung, die heute letztendlich in allen Fotosystemen gemacht wird.

29
00:03:46,000 --> 00:03:53,000
Es sei denn, Sie haben irgendwelche industriellen Anwendungen, wo es letztendlich nicht darauf ankommt, dass das Bild schön aussieht.

30
00:03:53,000 --> 00:04:03,000
Wenn Sie verrauschte Bilder haben, dann wollen Sie vielleicht Rauschen entfernen.

31
00:04:04,000 --> 00:04:11,000
Also hier ein Bild, auf dem offensichtlich Rauschen drauf ist.

32
00:04:11,000 --> 00:04:24,000
Sie können mit Methoden der Bildverarbeitung versuchen zu schätzen, in einem Bereich, welchen Wert der Sensor eigentlich haben sollte, wenn das ganze Signal rauschfrei wäre.

33
00:04:24,000 --> 00:04:31,000
Dann könnten Sie hier so ein rauschreduziertes Bild berechnen.

34
00:04:31,000 --> 00:04:46,000
Während hier die Antwort auf die Frage, welches Bild ist das bessere, aus meiner Sicht ganz klar ist, das rechte Bild, das verbesserte Bild ist das bessere,

35
00:04:46,000 --> 00:04:57,000
ist in meiner Welt die Antwort auf die gleiche Frage, welches Bild ist das bessere, das verrauschte oder das entrauschte Bild, hier nicht so klar zu beantworten.

36
00:04:57,000 --> 00:05:06,000
Auf mich macht dieses verrauschte Bild irgendwo einen lebendigeren und schärferen Eindruck.

37
00:05:06,000 --> 00:05:14,000
Das entrauschte Bild auf der rechten Seite, da sieht alles so ein bisschen fleckig aus.

38
00:05:14,000 --> 00:05:21,000
Wir als Mensch sind durchaus in der Lage zu erkennen, dass Herr Einstein nicht so im Gesicht aussah, wie er da aussieht.

39
00:05:21,000 --> 00:05:28,000
Das würde uns echt wundern, wenn er in der Realität so aussehen würde. Wir filtern das mit unserem visuellen System irgendwo weg.

40
00:05:28,000 --> 00:05:38,000
Aber hier, dieses Schäckige im Gesicht, da kann man sich natürlich, wenn man nicht weiß, wo die Effekte herkommen, fragen, was hat er denn da im Gesicht, hat er ein Hautproblem?

41
00:05:38,000 --> 00:05:46,000
Letztendlich, ob das linke oder das rechte Bild das richtige ist, hängt dann stark vom Anwendungsfall ab.

42
00:05:46,000 --> 00:05:57,000
Zur Bildverarbeitung gehört auch das, was Sie bei Photoshop oder anderen Bildverarbeitungssystemen als Funktion mit drin haben,

43
00:05:57,000 --> 00:06:06,000
dass Sie ein Foto dann mithilfe von Verarbeitungsalgorithmen mehr oder weniger automatisch in etwas umwandeln,

44
00:06:06,000 --> 00:06:16,000
was zum Beispiel aussieht wie ein Ölgemälde oder als wenn das einer mit Mundstiften gemalt hätte, diese Szene.

45
00:06:16,000 --> 00:06:26,000
Hier geht es ja letztendlich nur um eine Veränderung der Farbe. Sie können die drei Bilder übereinanderlegen, die Geometrie, der Ort, wo zum Beispiel diese Linie ist,

46
00:06:26,000 --> 00:06:32,000
der ist an allen Bildern gleich. Da gibt es jetzt keine künstlerische Freiheit. Aber wie diese einzelnen Linien dargestellt werden,

47
00:06:32,000 --> 00:06:41,000
das ist hier durch verschiedene Algorithmen unterschiedlich dargestellt worden.

48
00:06:41,000 --> 00:07:01,000
Es gibt auch Bildverarbeitung, hier im Beispiel vom Flughafen letztendlich, wo etwas vorgegaukelt wird, was der Sensor gar nicht tut.

49
00:07:01,000 --> 00:07:13,000
Ein Röntgenbild oder ein Nacktscanner, wie Sie ihn vielleicht auch vom Flughafen kennen, der erzeugt letztendlich Grauwertbilder.

50
00:07:13,000 --> 00:07:27,000
Pro Bildpunkt gibt es einen Sensorwert. Den können Sie natürlich auch als Rotfarbe interpretieren, aber letztendlich wird da nur eine Komponente, ein Frequenzband abgebildet.

51
00:07:28,000 --> 00:07:42,000
Nun können Sie dieses Signal durchaus aber auch farblich verändern. Das sehen Sie dann manchmal im Flughafen, wenn Sie die Gelegenheit haben, auf das Röntgenbild Ihres Gepäcks zu schauen,

52
00:07:42,000 --> 00:07:52,000
dass so ein Grauwertbild letztendlich farblich dargestellt wird, weil man dann zum Beispiel weiß, dass gewisse Bänder,

53
00:07:52,000 --> 00:08:00,000
also hier haben wir jetzt mal aufgezeichnet ein Grauwertbild, eine Grauwertamplitude und nach oben die Amplitude,

54
00:08:00,000 --> 00:08:08,000
dann wissen Sie, bei gewissen Amplitudenwerten in dem Röntgenbild, können Sie zum Beispiel Exklusivstoffe haben,

55
00:08:08,000 --> 00:08:17,000
dann werden diese Röntgenamplituden in einer Farbe dargestellt, die dann dem Betrachter ins Auge fällt.

56
00:08:17,000 --> 00:08:25,000
Das ist dann letztendlich Image Enhancement. Das können Sie machen, indem Sie den Kontrast verändern. Das können Sie von Ihrem Fernseher, da können Sie den Kontrast einstellen.

57
00:08:25,000 --> 00:08:35,000
Sie können das aber auch durch Falschfarbendarstellungen machen. Das wird auch im medizinischen Bereich sehr häufig eingesetzt.

58
00:08:36,000 --> 00:08:44,000
Genauso können Sie irgendwelche Analysedaten, die Sie aus Bildern haben, farblich darstellen.

59
00:08:44,000 --> 00:08:54,000
Hier ein Beispiel, der ist farblich dargestellt, die Verschiebung der Erde aufgrund eines Erdbebens.

60
00:08:55,000 --> 00:09:08,000
Die Interpretation dieses Bildes, das wir hier haben, wird dann gegeben durch diesen Kreis hier,

61
00:09:08,000 --> 00:09:14,000
der uns letztendlich aufgrund der Farbe angibt, in welche Richtung hat sich die Erde verschoben.

62
00:09:14,000 --> 00:09:24,000
Je nachdem, was Sie da für eine Darstellung haben, häufig wird dann auch noch die Amplitude, die Größe der Verschiebung in der Farbintensität dargestellt.

63
00:09:24,000 --> 00:09:28,000
Das ist jetzt in diesem Beispiel nicht ganz so optimal zu sehen, aber Sie können sich das vorstellen,

64
00:09:28,000 --> 00:09:41,000
dass man dann irgendwo von Rot die Richtung ablesen kann und aus der Intensität des Rots dann auch die Menge der Verschiebungen in die eine oder andere Richtung.

65
00:09:42,000 --> 00:09:49,000
Das ist offensichtlich eine Bildverbesserung oder eine Bildverarbeitung, wo Sie dann gewisse Dinge darstellen wollen,

66
00:09:49,000 --> 00:09:52,000
die im Originalbild an sich eigentlich gar nicht zu sehen sind.

67
00:09:52,000 --> 00:10:03,000
Ja, medizinische Bildverarbeitung ist auch ein Thema.

68
00:10:03,000 --> 00:10:13,000
Da gibt es die medizinische Bildverarbeitung, die dafür da ist, um zu sehen, was da ist.

69
00:10:13,000 --> 00:10:20,000
Freundchenbilder, Ultraschallbilder, das haben Sie vielleicht bei Ihren älteren Freunden gesehen,

70
00:10:20,000 --> 00:10:24,000
wenn da Kinder zur Welt kommen oder im Entstehen sind.

71
00:10:24,000 --> 00:10:28,000
Dann werden von den werdenden Eltern gerne Ultraschallbilder gezeigt.

72
00:10:28,000 --> 00:10:36,000
Auf diesen Ultraschallbildern selbst sieht man als Laie häufig relativ wenig.

73
00:10:37,000 --> 00:10:46,000
Aber für den Endverbraucher, das wären dann die werdenden Eltern, werden dann auch durchaus Algorithmen angeschmissen,

74
00:10:46,000 --> 00:10:51,000
die aus den sehr, sehr verrauschten Ultraschallbildern, wo man gar nicht so viel erkennen kann,

75
00:10:51,000 --> 00:11:00,000
dann Bilder erzeugt, die letztendlich nur entstehen konnten, weil die Algorithmen wissen,

76
00:11:00,000 --> 00:11:04,000
es handelt sich um einen menschlichen Fötus, der da abgebildet wird.

77
00:11:04,000 --> 00:11:09,000
Dann wird dieses Modell mit den Daten zusammengebracht und rauskommt etwas,

78
00:11:09,000 --> 00:11:15,000
wo Sie dann auch die Finger und die Zehen erkennen können.

79
00:11:15,000 --> 00:11:19,000
Wenn Sie mal in die Situation kommen und Sie gucken sich die Ultraschallbilder an,

80
00:11:19,000 --> 00:11:24,000
so wie sie auf dem Gerät zu sehen sind, während der Arzt den Sensor über den Bauch bewegt,

81
00:11:24,000 --> 00:11:32,000
dann werden Sie merken, da ist sehr viel Fantasie nötig, um zu dem Bild, was Sie hier sehen, zu kommen.

82
00:11:34,000 --> 00:11:42,000
Ein anderes Beispiel kann man sich ja kaum vorstellen, aber Deutschland will das Bundesamt wissen,

83
00:11:42,000 --> 00:11:48,000
wo stehen Häuser, wo sind Straßen und wo haben wir grünen Flächen, wo sind Ackerflächen, Waldflächen,

84
00:11:48,000 --> 00:11:55,000
niedrige Vegetation, hohe Vegetation und diese Information bekommt das Bundesministerium von den Ländern.

85
00:11:55,000 --> 00:12:00,000
Die haben da die Hoheit. Aber die Länder arbeiten nicht immer ordentlich,

86
00:12:00,000 --> 00:12:05,000
also fliegt dann auch die Bundesbehörde mit Flugzeugen über das Land fotografiert

87
00:12:05,000 --> 00:12:11,000
und dann gibt es Bildanalysealgorithmen, die extrahieren, wo haben wir Siedlungsflächen,

88
00:12:11,000 --> 00:12:16,000
wo haben wir Wasserflächen, wo haben wir Straßen, wo haben wir Acker und die Ergebnisse dieser automatischen Analyse

89
00:12:16,000 --> 00:12:22,000
werden dann verglichen mit den Karten, die die Länder liefern.

90
00:12:22,000 --> 00:12:26,000
Das ist dann letztendlich eine Qualitätskontrolle. Der Bund bezahlt für diese Karten, die Länder liefern.

91
00:12:26,000 --> 00:12:32,000
Die Länder wollen es möglichst billig haben, liefern also die Karten vielleicht im 5-Jahres-Rhythmus

92
00:12:32,000 --> 00:12:38,000
und verkaufen dann dem Bund das mit den Worten, das ist alles aktuell.

93
00:12:38,000 --> 00:12:41,000
Ja, hier haben wir ein Beispiel für die medizinische Bildverarbeitung,

94
00:12:41,000 --> 00:12:44,000
hier jetzt nicht im Sinne von Falschfarben-Darstellung.

95
00:12:44,000 --> 00:12:49,000
Ja, das Bild, was hier zugrunde liegt, das war vielleicht ein Schwarz-Weiß-Bild

96
00:12:49,000 --> 00:12:55,000
und das wurde dann eben in Weiß-Blau umkodiert.

97
00:12:55,000 --> 00:12:59,000
Aber hier geht es jetzt darum, zum Beispiel die Zellkerne zu zählen.

98
00:12:59,000 --> 00:13:04,000
Das sind Methoden der Bildverarbeitung, die so etwas ermöglichen.

99
00:13:04,000 --> 00:13:10,000
Wir haben letztendlich den Schritt von hier nach hier gemacht und wir haben hier so Linien eingezogen

100
00:13:10,000 --> 00:13:16,000
und das Kriterium für diese Linien ist letztendlich, sie sind immer mitten zwischen zwei Zellkernen

101
00:13:16,000 --> 00:13:20,000
und wenn wir jetzt wissen, wie viele von diesen Gebieten sie haben,

102
00:13:20,000 --> 00:13:23,000
dann wissen wir auch, wie viele Zellen sie haben oder wie viele Zellkerne sie haben.

103
00:13:27,000 --> 00:13:35,000
Das ist ein Problem, was Sie für viele mikroskopische Bilder automatisch lösen können,

104
00:13:35,000 --> 00:13:38,000
aber das bedeutet nicht, dass das überall gemacht wird.

105
00:13:38,000 --> 00:13:44,000
Es gibt viele medizinische Fakultäten, wo ein Großteil der Doktorarbeit darin besteht,

106
00:13:44,000 --> 00:13:51,000
solche Bilder hier per Hand auszuwerten, obwohl man das auch automatisch machen könnte.

107
00:13:51,000 --> 00:13:57,000
Aber wenn die, die Bildverarbeitung können und die, die Medizin machen, nicht aufeinandertreffen,

108
00:13:57,000 --> 00:14:04,000
dann hat der, der die Bildverarbeitung macht, keine Daten, auf denen er seine Algorithmen entwickeln kann

109
00:14:04,000 --> 00:14:07,000
und der, der die Daten auswerten soll, macht es per Hand.

110
00:14:08,000 --> 00:14:17,000
Im Bereich der industriellen Bildverarbeitung oder der Produktionskontrolle ist Bildverarbeitung auch etwas sehr Wichtiges.

111
00:14:17,000 --> 00:14:24,000
Zum Beispiel eine Ausgründung unseres Instituts, WISKOM, stellt Maschinen her,

112
00:14:24,000 --> 00:14:27,000
bei denen die Bestückung von Leiterplatten überprüft wird.

113
00:14:27,000 --> 00:14:34,000
Leiterplatten werden ja heute automatisch bestückt und verlötet und meistens klappt das auch,

114
00:14:35,000 --> 00:14:37,000
aber hin und wieder geht es daneben.

115
00:14:37,000 --> 00:14:47,000
Als Lieferant einer bestückten elektrischen Platine müssen Sie aber letztendlich sicherstellen,

116
00:14:47,000 --> 00:14:51,000
dass von einer Million Platinen, die Sie liefern, maximal eine kaputt ist.

117
00:14:51,000 --> 00:14:56,000
Wenn Sie mehr Ausschuss haben, wird Ihr Kunde extrem unzufrieden,

118
00:14:56,000 --> 00:15:03,000
der ja diese Platinen in irgendwelche größeren Geräte reinbaut und die Kosten dann womöglich ein paar tausend Euro.

119
00:15:03,000 --> 00:15:07,000
Und wenn die dann zur Reparatur kommen, fallen immense Kosten an.

120
00:15:07,000 --> 00:15:13,000
Also müssen Sie an jeder Stelle des Produktionsprozesses eine Qualitätskontrolle durchführen.

121
00:15:13,000 --> 00:15:19,000
Früher überwiegend durch Menschen, heute nach Möglichkeit da, wo es geht, automatisch.

122
00:15:19,000 --> 00:15:24,000
Und da bietet sich dann auch wieder die Bildverarbeitung an, mit der Sie dann erkennen können,

123
00:15:24,000 --> 00:15:28,000
zum Beispiel durch Vergleich einer Musterplatine, die ordentlich aussieht,

124
00:15:28,000 --> 00:15:39,000
mit einer Platine, die gerade aus der Produktion herauskommt, können Sie dann feststellen, ob da Fehler sind oder nicht.

125
00:15:39,000 --> 00:15:46,000
Da können Sie dann auch nicht nur Teile identifizieren, die offensichtlich falsch platziert sind,

126
00:15:46,000 --> 00:15:51,000
sondern Sie können auch die eine oder andere Lötstelle, die nicht sauber ist, identifizieren.

127
00:15:52,000 --> 00:16:00,000
Und damit erhalten Sie eine Qualitätskontrolle mit einer Qualität, die häufig viel besser ist als das, was Sie als Mensch erreichen können.

128
00:16:03,000 --> 00:16:07,000
Überwachung ist auch ein großes Thema der Bildverarbeitung.

129
00:16:07,000 --> 00:16:14,000
Sie wissen, die Kameras, mit denen Sie Ihr Haus oder Ihr Umfeld überwachen können, nehmen zu.

130
00:16:14,000 --> 00:16:16,000
Aber wer guckt sich denn das Ganze an?

131
00:16:16,000 --> 00:16:22,000
Ich meine, es ist ja schön, wenn Sie eine Kamera haben, mit der Sie aufzeichnen und sehen, wer bei Ihnen am Haus vorbeiläuft.

132
00:16:22,000 --> 00:16:29,000
Aber das kann man sich angucken und spätestens nach fünf Minuten langweilen Sie sich, weil meistens passiert ja nichts.

133
00:16:29,000 --> 00:16:40,000
Also brauchen Sie auch hier wieder automatische Algorithmen, die Alarm schlagen, wenn etwas passiert, was Sie nicht wünschen oder was ungewöhnlich ist.

134
00:16:40,000 --> 00:16:49,000
Ja, Sie können einen Menschen vor eine Videowand setzen mit vielleicht 20 Monitoren.

135
00:16:49,000 --> 00:16:55,000
Aber, das ist auch klar, nach einer Stunde ist der Mensch, der davor sitzt, nicht mehr aufmerksam.

136
00:16:55,000 --> 00:16:59,000
Natürlich, wenn der ganze Bildschirm anfängt zu flackern, wird er das sehen.

137
00:16:59,000 --> 00:17:04,000
Aber wenn sich einer langsam irgendwo durchs Bild schleicht, womöglich auch nur klein,

138
00:17:04,000 --> 00:17:10,000
weil die Überwachungskameras ja häufig ein großes Gebiet überwachen sollen, dann wird er das typischerweise übersehen.

139
00:17:10,000 --> 00:17:14,000
Automatische Bildverarbeitung würde hier helfen.

140
00:17:22,000 --> 00:17:32,000
Ein ganz verbreitetes Bildverarbeitungsproblem ist die Gesichtsdetektion.

141
00:17:33,000 --> 00:17:39,000
Die meisten Kameras, die es heute gibt, die detektieren automatisch Gesichter.

142
00:17:39,000 --> 00:17:47,000
Sie nutzen Ihnen da einen Rahmen um, wenn Sie entsprechend die Benutzerschnittstelle konfiguriert haben.

143
00:17:47,000 --> 00:17:52,000
Und stellen dann auch automatisch auf dieses Gesicht scharf.

144
00:17:52,000 --> 00:18:00,000
Anderes Beispiel. Viele Kameras sind in der Lage, dass sie automatisch einen QR-Code erkennen, sobald er im Bild ist.

145
00:18:00,000 --> 00:18:03,000
Auch das ist Bildverarbeitung.

146
00:18:03,000 --> 00:18:10,000
Hier haben wir Gesichtserkennung. Es gibt Algorithmen, die machen dann eben einen QR-Code.

147
00:18:10,000 --> 00:18:14,000
Erstmal eine Detektion. Da ist ein QR-Code.

148
00:18:14,000 --> 00:18:23,000
Und dann in einem zweiten Schritt wird bei den QR-Codes dann auch noch die Analyse gemacht, um festzustellen, was zeigt denn dieser QR-Code.

149
00:18:24,000 --> 00:18:28,000
Bei Gesichtern ist es normalerweise so, dass sie nur eine Gesichtsdetektion machen.

150
00:18:28,000 --> 00:18:34,000
Eine Gesichtserkennung im Sinne von, wer ist das denn, hoffen wir ja alle, dass das nicht automatisch passiert.

151
00:18:34,000 --> 00:18:43,000
Und wenn Sie mal Ihre Consumer-Kamera nehmen, die Gesichter detektiert, und dann drehen Sie die mal um 180 Grad,

152
00:18:43,000 --> 00:18:47,000
dann werden Sie feststellen, dass plötzlich die Gesichtsdetektion nicht mehr so gut funktioniert.

153
00:18:47,000 --> 00:18:55,000
Das ist dann auch ein Zeichen dafür, dass die Algorithmen häufig davon ausgehen, dass gewisse Gebenheiten gegeben sind.

154
00:18:55,000 --> 00:18:58,000
Also die Augen sind über dem Mund.

155
00:18:58,000 --> 00:19:01,000
Wenn Sie die Kamera drehen, dann sind Sie erstmal in dem Bild andersrum.

156
00:19:01,000 --> 00:19:11,000
Handschriftenerkennung.

157
00:19:11,000 --> 00:19:17,000
Ziffernerkennung ist ein Problem, was uns als Menschen wahrscheinlich gar nicht so bewegt.

158
00:19:17,000 --> 00:19:21,000
Aber die Post hat es schon vor 30 Jahren bewegt.

159
00:19:21,000 --> 00:19:27,000
Da haben sie schon Systeme eingesetzt, mit denen sie versucht haben, die Postleitzahlen automatisch zu lesen.

160
00:19:27,000 --> 00:19:32,000
Später dann auch die Straßen und die Hausnummern.

161
00:19:32,000 --> 00:19:39,000
In Deutschland war es letztendlich die Post, die das Ganze vorangetrieben hat.

162
00:19:39,000 --> 00:19:47,000
In den USA waren es die Banken, denn der Bankverkehr in den USA wurde ja bis vor kurzem praktisch per Post abgewickelt.

163
00:19:47,000 --> 00:19:53,000
Wenn Sie jemandem in Deutschland, würde man sagen, Geld überweisen wollen, dann haben Sie in den USA einen Scheck geschrieben.

164
00:19:53,000 --> 00:19:56,000
Mit der Hand.

165
00:19:56,000 --> 00:20:01,000
Sie haben da dann einen Briefschubschlag geöffnet, Scheck rein, zugeklebt, Briefmarke drauf.

166
00:20:01,000 --> 00:20:05,000
Und dann hat der Empfänger diesen Scheck bekommen, den er dann zu seiner Bank getragen hat.

167
00:20:05,000 --> 00:20:16,000
Das hatte dann auch den Vorteil, dass das Porto in den USA viel günstiger war als in Deutschland, weil der ganze Bankverkehr per Post abgewickelt wurde.

168
00:20:17,000 --> 00:20:32,000
Es gibt Fingerabdruckscanner, es gibt Iris-Scanner, es gibt gewisse Merkmale, die sind eindeutig und geeignet, um Personen zu identifizieren.

169
00:20:32,000 --> 00:20:39,000
Ich habe es zuerst vor vielen, vielen Jahren in irgendwelchen James-Bond-Filmen gesehen, aber mittlerweile gibt es diese Geräte, die auch wirklich funktionieren.

170
00:20:39,000 --> 00:20:50,000
Die erkennen dann letztendlich das eindeutige, einzigartige Muster der Iris und gleichen das dann ab mit einer Datenbank.

171
00:20:50,000 --> 00:20:59,000
Und wenn Sie dann Iris sehen, die Sie auch in der Datenbank abgespeichert haben, dann wird letztendlich dem Bild, was gerade aufgenommen wird, der Name aus der Datenbank zugeordnet.

172
00:20:59,000 --> 00:21:04,000
Und dann passiert eben das, was gemäß den Regeln des Systems zu passieren hat.

173
00:21:05,000 --> 00:21:16,000
Und was Sie hier sehen, sind verschiedene Schritte, die hier gemacht wurden. Hier wurden zum Beispiel die Augenlider, da wurden die Kanten erkannt.

174
00:21:16,000 --> 00:21:24,000
Die Pupille wurde markiert, wurde hier durch den weißen Rand markiert, die Iris außenrum.

175
00:21:24,000 --> 00:21:33,000
Was Sie hier auch sehen, ist, dass die Pupille durch einen schönen Kreis abgegrenzt ist und die Iris auch.

176
00:21:33,000 --> 00:21:39,000
Das werden Sie mit Bildverarbeitung ohne Vorwissen nicht hinbekommen.

177
00:21:39,000 --> 00:21:49,000
Aber wir haben ja Vorwissen, die Pupille muss rund sein, also werden Sie dann Methoden der Bildverarbeitung versuchen, einen Kreis um diese schwarze Pupille zu legen.

178
00:21:49,000 --> 00:21:53,000
Und mit dem Wissen, das muss ein Kreis sein, kriegt man auch so etwas Schönes Glattes hin.

179
00:21:53,000 --> 00:22:05,000
Wenn wir uns jetzt ein Bild angucken, ich sage jetzt mal von einem Bildpunkt zum nächsten, ohne globale Sicht, dann werden Sie sicherlich hier auch eine Kante um die Pupille legen können, aber sie wird nicht kreisrund werden.

180
00:22:06,000 --> 00:22:22,000
Vieles, was wir als Mensch so in Bildern oder in dem, was wir sehen, wahrnehmen und was wir intuitiv richtig machen, ist sehr, sehr stark geprägt durch Vorwissen, durch Modelle, die wir im Laufe unserer Entstehungsgeschichte, also von Geburt an, irgendwie gelernt haben.

181
00:22:22,000 --> 00:22:32,000
Und wenn wir dann irgendwas sehen und wir wissen, das ist eine Kameralinse, dann gehen wir automatisch davon aus, dass das ein perfekter Kreis sein muss.

182
00:22:32,000 --> 00:22:44,000
Und dieses Vorwissen, was wir so intuitiv haben, ist etwas, was ein Computer, der jetzt irgendwelche Bilder analysieren soll, natürlich nicht hat. Es sei denn, Sie programmieren es rein.

183
00:22:44,000 --> 00:23:04,000
Und dieses Reinprogrammieren von Vorwissen ist letztendlich etwas, was schwierig ist oder was auch dazu führt, dass Sie ein Computer Vision System, wenn Sie es in einer dem System unbekannten Umgebung benutzen, leicht in die Irre führen können.

184
00:23:04,000 --> 00:23:16,000
Das ist auch das, was autonomes Fahren so schwierig macht, weil Sie letztendlich diesem System nicht alle Situationen des Fahrens zeigen können.

185
00:23:16,000 --> 00:23:35,000
Es ist immer mal irgendwie, was das System nicht gesehen hat. Und sei es, dass Sie irgendwo über das Land fahren und dann plötzlich eine Schafherde auf den Verkehrskreise ihre Runden zieht. So etwas haben Sie wahrscheinlich Ihrem autonomen Fahrsystem vorher nicht gezeigt. Woher soll es dann wissen, was es da zu machen hat?

186
00:23:35,000 --> 00:23:40,000
Weil ja letztendlich das übergeordnete Wissen, was wir als Mensch haben, nicht da ist.

187
00:23:40,000 --> 00:23:56,000
Bilder können Sie analysieren, können Sie ja verändern. Sie können auch Bilder zusammensetzen. Das ist das Konzept des Mosaiks. Das kennen Sie auch von Ihren Handys zum Beispiel.

188
00:23:57,000 --> 00:24:10,000
Da können Sie sagen, Sie wollen ein Mosaik haben, dann halten Sie die Kamera irgendwo hin und bewegen sie langsam von links nach rechts oder von oben nach unten, was auch immer Ihre Software da erlaubt. Und dann werden die Bilder zusammengesetzt.

189
00:24:11,000 --> 00:24:35,000
Hier ein Beispiel, hier oben 33 Bildern, wo das erzeugt. Da können Sie einen großen Blickwinkel erfassen. Und das funktioniert letztendlich dadurch, dass die Bilder, die nacheinander aufgenommen werden, die müssen sich irgendwie überlappen. Und dann werden sie aufgrund der Überlappung zusammengesetzt.

190
00:24:35,000 --> 00:24:50,000
Und dann kann man eben verschiedene Dinge erreichen. Sie sehen hier die Perspektive von links nach rechts. Sieht irgendwie ein bisschen komisch aus. Das kann man dann später noch entzerren. Und dann kriegt man auch durchaus Panorama-Bilder, die man an der Wand gut aufhängen kann.

191
00:24:50,000 --> 00:25:05,000
Auch das hier unten ist offensichtlich ein Panorama-Bild, weil Sie eben sehen, eine normale Kamera würde diesen Bereich und diesen Bereich zusammen nicht so gekrümmt aufnehmen, wie das hier den Eindruck macht.

192
00:25:05,000 --> 00:25:30,000
Mit Bildern können wir nicht nur Bilder darstellen, sondern auch andere Informationen. Also hier in diesem Beispiel Tiefeninformationen. Die Microsoft Kinect nimmt ein Bild auf.

193
00:25:30,000 --> 00:25:42,000
Und was wir dann hier sehen, ist für jeden Bildpunkt eine Entfernung von diesem Bildpunkt, von dem Objekt, was auf dem Bildpunkt dargestellt wird, zur Kamera.

194
00:25:42,000 --> 00:26:00,000
Ohne dass es hier jetzt drunter steht, weil wir ein Verständnis dafür haben, wie diese Szene wohl aussieht. Nehmen wir also an, dass dieses rötliche bedeutet große Entfernung. Grünliche, gelbe hier ist dann vielleicht eine mittlere Entfernung.

195
00:26:01,000 --> 00:26:12,000
Hellblau dicht dran, dunkelblau ganz dicht dran. Da ist also letztendlich die Abstandsinformation in Farbinformationen modiert worden.

196
00:26:12,000 --> 00:26:30,000
Fotografie ist vielleicht so ein bisschen im Bereich der schönen Künste anzuordnen, aber Sie können mit optischen Systemen durchaus auch messen.

197
00:26:30,000 --> 00:26:45,000
Dann gibt es den Begriff der Fotogrammetrie. Damit wird das Land, die Erde vermessen, Gebäude werden vermessen. Es gibt auch die Nahbereichsfotografie. Da wird dann zum Beispiel überprüft, ob die Karosserie Ihres Autos ordentlich geformt ist.

198
00:26:45,000 --> 00:27:02,000
Da gibt es dann kalibrierte Kamerasysteme, wo Sie wirklich exakt die mathematische Abbildung von der Szene zu einem Bildpunkt, zu jedem Bildpunkt, den der Sensor hat, beschreiben.

199
00:27:02,000 --> 00:27:15,000
Wenn Sie so eine Kamera kalibriert haben, können Sie durch Messen von Bildpunktabständen im Bild schließen auf reale Abstände in der realen Welt.

200
00:27:15,000 --> 00:27:31,000
Da ist die optische Messtechnik natürlich eine schöne Sache. Wenn Sie das, was Sie vermessen wollen, im Bild identifizieren können, weil Sie da irgendwelche Markierungen haben, weil es da irgendwelche Kanten gibt, dann ist die optische Messtechnik natürlich toll, weil sie ist berührungslos.

201
00:27:31,000 --> 00:27:46,000
Sie können mit einem Bild einen recht großen Bereich erfassen. Sie müssen nicht mit dem Zollstock hier messen und dann hier und hier und hier. Das machen wir mit einem Bild und dann lassen wir den Computer schnell über das Bild laufen und der sagt Ihnen, wie Ihre Messwerte aussehen.

202
00:27:46,000 --> 00:27:55,000
Wenn Sie messen wollen und Sie haben ein Gefühl dafür, dass Sie das womöglich mit einer Kamera machen können, machen Sie es. Das ist meistens schneller und preiswerter.

203
00:27:55,000 --> 00:28:12,000
Die Achsvermessung, Spureinstellung von Autos wird mittlerweile optisch gemacht. Was Sie hier sehen, sind auch Marker, die letztendlich der optischen Bildverarbeitung helfen, um irgendwelche Orte zu vermessen.

204
00:28:12,000 --> 00:28:30,000
Diese Marker hier, die sind dann mechanisch angekoppelt an das Rad, was Sie da vermessen wollen. Auch wenn Ihre Radarsensoren beim Auto, die müssen ja irgendwie genau ausgerichtet sein, damit sie als Abstandssystem funktionieren. Aber wenn die vermessen werden, wird das auch mithilfe von optischen Verfahren gemacht.

205
00:28:30,000 --> 00:28:50,000
Wir als Mensch sind in der Lage, aus den 2D-Bildern, die wir mit dem Auge aufnehmen, 3D-Rekonstruktionen zu machen. Wir können einen Abstand erfassen. Das muss dann ja auch mit Kamerabildern möglich sein.

206
00:28:50,000 --> 00:29:14,000
Das kann man auch machen. Das ist die 3D-Rekonstruktion oder die Fotogrammetrie, wo Sie einfach mit einer Kamera, die sich bewegt und damit verschiedene Blickwinkel auf ein Objekt bekommt und damit die Form erfasst. Oder mit mehreren Kameras, die dann aus verschiedenen Winkeln das gleiche Objekt zeigen. Mit diesen Systemen können Sie dann auch 3D-Rekonstruktionen machen.

207
00:29:15,000 --> 00:29:37,000
Wir als Mensch können das ja auch. Wenn Sie ein unbekanntes Objekt haben wollen, die Form erfassen, bewegen Sie meist Ihren Kopf, tasten somit das Objekt aus verschiedenen Blickwinkeln ab, rekonstruieren dann in Ihrem Kopf die 3D-Form. Die Abbildung ist mathematisch beschreibbar und dann können Sie es auch mit Computern machen.

208
00:29:37,000 --> 00:30:01,000
Navigation ist ein ganz heißes Thema. Nicht nur die Navigation, die Sie mit Ihrem Handy machen. Sie sind irgendwo und sagen, da will ich hin und dann wird Ihnen gezeigt, wie Sie in der Straße da sind, sondern auch Navigation in unbekannten Terrain. Also Roboter sollen sich irgendwo zurechtfinden, sollen von A nach B navigieren, sollen dabei nichts umfahren.

209
00:30:01,000 --> 00:30:25,000
Das ist auch ein visuelles Problem, was zu lösen ist. Das nennt sich dann Visual Simultaneous Localization and Mapping. Also der Roboter versucht sich zu lokalisieren, wo bin ich. Und dann bewegt er sich und versucht seine Umgebung zu erfassen.

210
00:30:25,000 --> 00:30:37,000
Die Lokalisierung, wo bin ich auf dem Planeten im Sinne von GPS-Koordinaten ist natürlich für viele Anwendungen nicht notwendig. Der Roboter in Ihrem Haus muss nicht wissen, ob Ihr Haus nun in Nordrhein-Westfalen oder in Niedersachsen steht.

211
00:30:37,000 --> 00:30:57,000
Aber er muss in der Lage sein, seine Umgebung zu erfassen und dann, wenn er fährt, muss er eben auf Hindernisse Rücksicht nehmen und er sollte nicht unbedingt das vergessen, was er gerade gesehen hat, bevor er losgefahren ist. Also er muss selbst in der Lage sein, eine Karte zu erstellen.

212
00:30:57,000 --> 00:31:09,000
Genauso wie Sie, wenn Sie in eine neue Umgebung kommen, dann ja auch hin und her gehen und gucken und irgendwann wissen Sie, wie Sie automatisch von A nach B kommen, ohne groß nachzudenken.

213
00:31:09,000 --> 00:31:29,000
Wenn Sie irgendwelche Gebäude haben, die besonders symmetrisch sind, Beispiel Hochhaus, Sie kommen aus dem Fahrstuhlschacht raus, dann wird es eine gewisse Zeit dauern, bis Sie wissen, ob Sie von welchem Fahrstuhl Sie gerade kommen, nach links oder rechts gehen müssen, um den kürzesten Weg zu Ihrem Büro zu finden.

214
00:31:29,000 --> 00:31:35,000
Die Probleme hat der Computer, die Probleme haben die Menschen, nichts Neues da.

215
00:31:35,000 --> 00:31:52,000
Fahrerassistenzsysteme ist natürlich ein Bildverarbeitungsproblem. Es gibt Tesla, die sagen, Kameras tun es alleine. Es gibt Mercedes, die dagegen halten und sagen, nein, wir wollen drei Sensorsysteme haben, damit wir uns auf zwei verlassen können.

216
00:31:52,000 --> 00:32:06,000
Die sagen, wir brauchen auch noch ein Radarsystem, wir brauchen ein LIDAR-System, aber keiner sagt, dass es ohne Kamera geht. Von daher sind sie mit digitaler Bildverarbeitung am richtigen Ort.

217
00:32:06,000 --> 00:32:31,000
Man will Fahrbahnmarkierungen erfassen, man will Objekte erfassen, die vor einem sind, man will wissen, wie schnell bewegen die sich, man will natürlich auch Menschen erkennen und was dann der nächste Schritt ist, man will wissen, was macht der als nächstes.

218
00:32:31,000 --> 00:32:57,000
Das kennen Sie alle. Wenn Sie mit dem Auto fahren, Sie sehen einen Fußgänger, der kann natürlich von einem Moment auf den anderen auf die Fahrbahn springen. Sie gehen davon aus, dass er das nicht macht. Aber wenn er irgendwie anfängt rumzueiern, dann wissen wir, es kann passieren, dass er jetzt doch auf den Zebrastreifen gehen will und Sie reagieren entsprechend im Sinne von, Sie nehmen den Fuß im Gas, bremsen vielleicht oder Sie hupen, je nachdem, was da so Ihre Mentalität ist.

219
00:32:57,000 --> 00:33:20,000
Und diese Erkennung der Intention, das ist etwas, was wir aufgrund unserer Erfahrung durchaus können. Das ist etwas, was für das automatische Fahren noch ein ganz, ganz großes Problem ist. Man ist mittlerweile in der Lage, Fußgänger zuverlässig zu erkennen, aber was macht er als nächstes? Er geht schnell auf die Kreuze zu, aber bleibt er dann stehen oder geht er weiter?

220
00:33:20,000 --> 00:33:35,000
Das ist etwas, was wir als Mensch intuitiv aufgrund der Beobachtung relativ gut erfahren, erfassen können, gegebenenfalls mit Blickkontakt zu unseren anderen Verkehrspartner, was dem Computer offensichtlich noch nicht so richtig gelingen kann.

221
00:33:35,000 --> 00:33:59,000
Ja und dann etwas, worüber viel gesprochen wird. Maschinelles Lernen mit neuronalen Netzwerken. Das wird häufig als das Heilmittel der Bildverarbeitung gesehen. Wir müssen jetzt nicht mehr so richtig wissen, wie die Welt funktioniert.

222
00:33:59,000 --> 00:34:20,000
Sie geben Ihrem neuronalen Netz im Rahmen dieser Vorlesung Bilder und Sie sagen dem neuronalen Netz, was es da erkennen soll, was das Ergebnis der Bildanalyse sein soll und dann trainieren Sie das Netz.

223
00:34:21,000 --> 00:34:46,000
Ja, das kann man machen. Und wenn man dann merkt, dass in so einem neuronalen Netz, wie auch immer das aufgebaut ist, also letztendlich gewichtete Additionen und Multiplikationen von irgendwelchen Zahlen und diese Ergebnisse werden dann durch nicht lineare Funktionen geschickt, wenn man dann weiß, dass man da durchaus ein paar hundert Millionen Parameter hat, die sich da einzustellen haben,

224
00:34:46,000 --> 00:35:07,000
dann kann man sich auch vorstellen, dass dieser Lernprozess von ich habe hier irgendwelche Daten und ich habe gewünschte Ergebnisse sehr, sehr viele Daten fordert. Das ist nicht zufällig, dass ein Mensch doch mehrere Jahre braucht, bis er letztendlich voll funktionsfähig ist.

225
00:35:08,000 --> 00:35:23,000
Und damit ist auch klar, dass es schwer ist, solche neuronalen Netze zu trainieren. Es geht für viele Anwendungsfälle, aber ein Allheilmittel ist es nicht. Wenn Sie etwas durch die Physik beschreiben können, dann haben Sie durchaus Vorteile.

226
00:35:24,000 --> 00:35:37,000
Ein anderes Bildverarbeitungsbeispiel im Painting. Sie haben irgendwelche Fotos. Ich habe vor ein paar Jahren geheiratet und dann gab es einen Fotografen und dann zeigte er uns Bilder und das war alles ganz schön.

227
00:35:38,000 --> 00:35:56,000
Ja, es ist ein schönes Bild. Und dann hat er uns das Originalbild gezeigt. Da war eine Mülltonne, da hat er noch Papier auf der Straße liegen lassen und alles Mögliche hatte er wegkritischiert, ohne dass man das erkennen konnte. Das sind Methoden des Inpaintings.

228
00:35:56,000 --> 00:36:17,000
Wenn Sie das Foto aufnehmen, ist das alles schön. Ein paar Jahre später haben Sie sich das vielleicht anders überlegt. Inpainting erlaubt es Ihnen einen Bereich, den Sie auf dem Bild rausschneiden. Sie sagen, diesen Bereich kenne ich nicht mehr, der soll jetzt plausibel ersetzt werden. Dann können Sie so ein Ergebnis erhaben.

229
00:36:18,000 --> 00:36:28,000
Ist das real? Ist hier wirklich die Stufe so durchgängig, wie das hier den Eindruck macht? Keine Ahnung. Beim Inpainting geht es darum, ein plausibles Ergebnis zu erzeugen.

230
00:36:28,000 --> 00:36:56,000
Wenn man mit mehreren Kameraansichten 3D-Szenen erzeugen kann, dann kann man sich auch vorstellen, dass man, wenn man mehrere Bilder hat, auf andere Art und Weise das Zwischenbild berechnen kann.

231
00:36:56,000 --> 00:37:10,000
Dass man dann aus mehreren Fotos letztendlich eine 3D-Szene berechnet, von der hat man dann mehrere Ansichten und dann kann man mit einer virtuellen Kamera durch diese Szene fahren.

232
00:37:11,000 --> 00:37:25,000
Dann können Sie sich ein synthetisches Video erzeugen. Und Sie können dann eben auch gegebenenfalls darauf achten, dass in diesem Video manche Dinge nicht drin sind.

233
00:37:25,000 --> 00:37:33,000
Also die Personen, die hier teilweise zu sehen sind, die haben wir denn hier nicht, weil da eine Textur ausgebildet wurde aus Bildern, wo die Person gerade nicht da war.

234
00:37:41,000 --> 00:38:00,000
Eines der erfolgreichsten Beispiele von Bildverarbeitung sind sicherlich die Barcode-Scanner. Gab es schon vor langer Zeit. Neuere Dinge sind, Ihr Auto sagt Ihnen, wie schnell Sie fahren dürfen.

235
00:38:01,000 --> 00:38:09,000
Also das Ende dieser Technologie wird sicherlich sein, wenn das Ministerium vorschreibt, dass ein Auto auch nicht schneller fahren darf, als das, was es erkannt hat.

236
00:38:09,000 --> 00:38:30,000
Ein Beispiel, was wir jetzt noch gar nicht hatten. Büroautomatisierung, Dokumentenanalyse, automatische Erkennung der Schrift, der Texte von einem gescannten Dokument.

237
00:38:31,000 --> 00:38:43,000
Das ist sicherlich etwas Wichtiges, worüber wir nicht gesprochen haben. Zur Bildverarbeitung kann man auch die Anwendung Bildkompression zählen.

238
00:38:43,000 --> 00:38:56,000
Jede digitale Kamera heute hat auch ein Kompressionsverfahren eingebaut, mit dem die Bilddaten, wie sie vom Sensor kommen, besonders effektiv beschrieben werden.

239
00:38:56,000 --> 00:39:06,000
JPEG haben Sie alle auf Ihrer Kamera. Die anderen Bereiche haben wir, glaube ich, alle erwähnt.

240
00:39:06,000 --> 00:39:20,000
So viel zu den Anwendungen. Digitale Bildverarbeitung ist das, womit wir uns hier beschäftigen.

241
00:39:20,000 --> 00:39:30,000
Die Abgrenzung ist manchmal ein bisschen schwierig. Stellen wir uns mal vor, was wir haben. Wir haben ein Bild.

242
00:39:31,000 --> 00:39:37,000
Und letztendlich am Ende des Tages will man Informationen zu diesem Bild haben.

243
00:39:37,000 --> 00:39:45,000
Dann gibt es verschiedene Schritte, die man macht, um zu diesen Informationen zu kommen.

244
00:39:45,000 --> 00:39:53,000
Da gibt es einmal die Bildverarbeitung, Bildverbesserung, Filterung, Rauschen wird aus dem Bild genommen, irgendwelche Übersteuerungen werden ausgerechnet.

245
00:39:54,000 --> 00:40:06,000
Im zweiten Schritt wollen Sie dann vielleicht irgendwelche Merkmale extrahieren. Sie wollen wissen, wo sind Kanten im Bild, wo sind besondere geometrische Formen, Geraden, Kreise.

246
00:40:06,000 --> 00:40:16,000
Man wird Merkmale extrahieren, man wird das Bild vielleicht segmentieren in Bereiche, die sind weiter weg oder dichter dran, wenn man so an ein Kinect-Bild denkt.

247
00:40:16,000 --> 00:40:27,000
Das sind dann noch Bildanalyseverfahren auf niederschwelliger Ebene, die kein höherwertiges Wissen benötigen.

248
00:40:27,000 --> 00:40:35,000
Die müssen nicht wissen, wir suchen jetzt Kreise, weil wir Bilder eines Menschen detektieren wollen.

249
00:40:37,000 --> 00:40:44,000
Und in meiner Welt sind diese beiden Bereiche dann der Bildverarbeitung, also auch dieser Vorlesung zuzuhören.

250
00:40:44,000 --> 00:40:56,000
Als nächsten Schritt gibt es dann die Bildanalyse oder Computer Vision. Da ist teilweise auch diese Bildanalyse, die Berechnung von irgendwelchen Merkmalen gehört mit dazu.

251
00:40:56,000 --> 00:41:01,000
Dann aber auch vor allen Dingen ganz stark die Bildinterpretation, also die Mustererkennung.

252
00:41:01,000 --> 00:41:12,000
Da werden dann 3D-Rekonstruktionen berechnet. Es werden Menschen erkannt, es werden Dosen von irgendwelchen Menschen erkannt.

253
00:41:12,000 --> 00:41:19,000
Es wird gesagt, diese Lötstelle ist defekt. Das wäre dann mehr der Bereich Computer Vision.

254
00:41:23,000 --> 00:41:31,000
Also die digitale Bildverarbeitung beschreibt letztendlich die ersten Schritte, die Sie machen müssen, wenn Sie ein Bild auswerten wollen.

255
00:41:32,000 --> 00:41:44,000
Oder Sie können es dann auch anders sagen. Wir haben einen Operator, der die Eingabe für Bild F nimmt und als Ausgabe bekommen Sie wieder ein Bild.

256
00:41:44,000 --> 00:41:52,000
Sie bekommen nicht die Aussage, an der Koordinate 100, 200 befindet sich ein Mensch, sondern Sie bekommen wieder ein Bild.

257
00:42:01,000 --> 00:42:15,000
Bildbearbeitung wird häufig so interpretiert, dass man sagt, man hat ein Bild, daraus kommt ein modifiziertes Bild, was aber letztendlich dem Eingangsbild entspricht.

258
00:42:15,000 --> 00:42:21,000
Und das Gleiche gilt auch für ein Video, also eine Bildfolge. Ein Video ist ja nur eine Aneinanderreihung von Bildern.

259
00:42:21,000 --> 00:42:28,000
Bildfolge rein, eine hellere, kontrastangepasste Bildfolge wieder raus.

260
00:42:29,000 --> 00:42:45,000
Bei der Bildverarbeitung wird das Bild so manipuliert, dass letztendlich einfache geometrische oder farbliche Informationen sichtbar werden.

261
00:42:45,000 --> 00:42:56,000
Also Sie könnten da Linien einzeichnen, Kreise einzeichnen, Sie könnten Rauschen aus dem Bild rausnehmen, im Sinne von, dass Sie es ganz stark vereinfachen.

262
00:42:56,000 --> 00:43:06,000
Also wir haben jetzt hier, wenn Sie mein Video sehen, da sehen Sie, ja, ich habe hier eine einfache Kamera, also wenn wir das mal nur als Helligkeitsbild betrachten würden,

263
00:43:06,000 --> 00:43:11,000
dann kriegen Sie 8 Bit pro Bildpunkt, 256 verschiedene Grauwerte.

264
00:43:11,000 --> 00:43:18,000
Wenn Sie dieses Bild jetzt vereinfachen, Sie versuchen vielleicht zu erkennen, wo bewegt sich etwas, wo bewegt sich nichts,

265
00:43:18,000 --> 00:43:26,000
und Sie haben dann am Ende ein Bild mit vielleicht 10 verschiedenen Grauwerten, dann ist das sicherlich etwas, was zur Bildverarbeitung gehört.

266
00:43:26,000 --> 00:43:32,000
Mit Computer Vision versucht man letztendlich eine Szenenbeschreibung zu erreichen.

267
00:43:32,000 --> 00:43:43,000
Da bewegt sich ein Mensch, Kopf, Arme, da ist eine Zäule im Gebäude oder da stehen Bücher im Regal.

268
00:43:43,000 --> 00:43:47,000
Das wäre dann etwas, was man mehr im Bereich Computer Vision anordnen würde.

269
00:43:51,000 --> 00:44:00,000
Als Mensch betreiben wir auch Computer Vision. Uns interessiert ja nicht so unbedingt, da ist jetzt die Farbe Rot, sondern da steht eine Rose.

270
00:44:00,000 --> 00:44:03,000
Das ist ja das, was wir als Mensch machen.

271
00:44:03,000 --> 00:44:12,000
Und das Rot können wir dann, wenn wir über die Straße gehen, oh, die Ampel ist rot, dann ordnen wir der Farbe Rot eine andere Bedeutung zu.

272
00:44:12,000 --> 00:44:17,000
Können wir als Mensch, wir sind da sehr, sehr flexibel an die verschiedenen Umgebungen.

273
00:44:17,000 --> 00:44:25,000
Computer Vision, Machine Vision wird häufig mit industrieller Bildverarbeitung assoziiert, können Sie aber auch in der Überwachungstechnik nehmen, ist egal.

274
00:44:25,000 --> 00:44:34,000
Wichtig, das funktioniert, wenn Sie definierte Umgebungsbedingungen haben oder spezialisierte Aufgaben.

275
00:44:35,000 --> 00:44:49,000
Die Universalität, die wir als Mensch mit unserem Bildverarbeitungssystem mitbringen oder uns im Laufe der Jahre erwerben, können Sie mit dem Computer heute nicht erreichen.

276
00:44:49,000 --> 00:44:54,000
Deswegen müssen Sie sich immer überlegen, welche Algorithmen in welcher Umgebung passen.

277
00:44:54,000 --> 00:44:58,000
Wenn die Umgebung noch nicht die richtige ist, ändern Sie die Umgebung.

278
00:44:59,000 --> 00:45:07,000
Leuchten Sie Ihre Szene entsprechend, haben Sie dann definierte Umgebungsbedingungen.

279
00:45:07,000 --> 00:45:17,000
Auch wenn Sie neuronale Netze trainieren, werden Sie um dieses Problem der definierten Umgebungsbedingungen oder der spezialisierten Aufgabe auf absehbare Zeit nicht drumherum kommen.

280
00:45:21,000 --> 00:45:27,000
Bildverarbeitung, Computer Vision geht vom Bild zur Szenenbeschreibung.

281
00:45:27,000 --> 00:45:32,000
Computergrafik, hier nur kurz erwähnt, nicht Teil dieser Vorlesung, ist der umgekehrte Weg.

282
00:45:32,000 --> 00:45:38,000
Sie haben eine Szenenbeschreibung, eine 3D-Welt, in einem Computerspiel wird die beschrieben, da haben Sie die Geometrie, Sie haben die Texturen.

283
00:45:38,000 --> 00:45:52,000
Und die Computergrafik sorgt dann dafür, dass dieses 3D-Modell zum Beispiel, oder 4D, wenn es auch zeitlich bewegt ist, dass das in eine Bildfolge umgerechnet wird, die wir dann auf einem Monitor sehen können.

284
00:45:57,000 --> 00:46:11,000
Bildverarbeitung hat viele Themen. Es beginnt alles mit der Bildaufnahme, die dann ein Bild und eine Bildfolge erzeugt.

285
00:46:11,000 --> 00:46:24,000
Ihr Handy wird dieses Bild als erstes erstmal komprimieren, mit JPEG. Das ist letztendlich nicht Teil dieser Vorlesung.

286
00:46:25,000 --> 00:46:32,000
Wir beschäftigen uns mit der Bildbearbeitung. Da gibt es spezielle Effekte. Wir machen ja aus einem Bild ein Ölgemälde.

287
00:46:32,000 --> 00:46:42,000
Das haben wir vorhin im Beispiel gesehen. Bildrekonstruktion oder Verbesserung, das sind Themen, mit denen wir uns beschäftigen, mit den speziellen Effekten nicht.

288
00:46:42,000 --> 00:46:46,000
Also alles, was hier blau ist, ist Teil der Vorlesung.

289
00:46:46,000 --> 00:46:54,000
Wenn Sie die Bilder jetzt irgendwie haben, dann können Sie eine geometrische Bildanalyse machen. Sie können versuchen, in den Bildern zu messen.

290
00:46:54,000 --> 00:46:59,000
Sie können versuchen, 3D-Rekonstruktionen zu machen, wenn Sie mehrere Bilder von der gleichen Umgebung haben.

291
00:46:59,000 --> 00:47:04,000
Das wären dann die Aufgaben der Fotogrammetrie, 3D-Rekonstruktion, Lokalisierung, Kartierung.

292
00:47:04,000 --> 00:47:08,000
Wenn Sie einen Roboter haben, wollen Sie durch unbekannte Umgebungen fahren. Nicht Teil dieser Vorlesung.

293
00:47:09,000 --> 00:47:16,000
Also geometrische Bildanalyse betreiben wir nicht. Wir betreiben aber die Bildanalyse, ohne die Geometrie zu berücksichtigen.

294
00:47:16,000 --> 00:47:21,000
Also eine Veränderungsseduktion. Veränderung detektieren Sie nur, wenn Sie zwei Zustände haben.

295
00:47:21,000 --> 00:47:25,000
Also Veränderungsseduktion geht offensichtlich nur, wenn Sie mindestens zwei Bilder haben.

296
00:47:25,000 --> 00:47:30,000
Wir wollen vielleicht irgendwelche Merkmale berechnen. Wo sind Kanten? Wo sind Graden?

297
00:47:30,000 --> 00:47:36,000
Wir wollen ein Bild segmentieren. Stellen Sie sich vor, Sie haben ein Luftbild.

298
00:47:36,000 --> 00:47:42,000
Sie wollen jetzt wissen, wo sind die Grünflächen? Wo sind die Gebäude? Wo ist die Industriefläche?

299
00:47:42,000 --> 00:47:48,000
Das wäre etwas, was man unter Segmentierung versteht. Eine Vereinheitlichung des Bildes.

300
00:47:48,000 --> 00:47:53,000
Es gibt die Bereiche der Szenenanalyse, Bildfolgen-Tracking.

301
00:47:53,000 --> 00:47:58,000
Im medizinischen Bereich, im orthopädischen Bereich wird es zunehmend interessanter,

302
00:47:58,000 --> 00:48:04,000
dass man letztendlich nicht mehr durch den Menschen feststellt, da geht jemand komisch.

303
00:48:04,000 --> 00:48:08,000
Sondern, dass man das automatisch macht. Das ist nicht nur für die Orthopädie wichtig.

304
00:48:08,000 --> 00:48:12,000
Das wird auch im Sport immer mehr gemacht. Das waren die Bewegungsabläufe.

305
00:48:12,000 --> 00:48:16,000
Früher hat man sie mit der Kamera aufgenommen. Heute nimmt man sie auch mit der Kamera auf.

306
00:48:16,000 --> 00:48:20,000
Aber die Algorithmen versuchen auch gleich zu erkennen, wie bewegt sich der Mensch?

307
00:48:20,000 --> 00:48:22,000
Macht er das da optimal?

308
00:48:22,000 --> 00:48:28,000
Wir werden auch geometrische Primitive suchen. Schon erwähnt, Kanten, Ecken, Graden, Kreise.

309
00:48:28,000 --> 00:48:32,000
Wir werden uns nicht mit der Mustererkennung beschäftigen.

310
00:48:32,000 --> 00:48:38,000
Das ist schon im Bereich des maschinellen Sehens.

311
00:48:44,000 --> 00:48:48,000
Wie sieht denn jetzt ein Bildverarbeitungssystem aus?

312
00:48:54,000 --> 00:48:58,000
Wir brauchen etwas, was wir sehen wollen.

313
00:48:58,000 --> 00:49:02,000
Das ist das Objekt oder die Szene.

314
00:49:06,000 --> 00:49:10,000
Das Licht dieser Szene fällt auf unseren Sensor.

315
00:49:14,000 --> 00:49:18,000
Damit das Ganze funktioniert, brauchen wir Beleuchtung.

316
00:49:18,000 --> 00:49:22,000
Die Beleuchtung kann Teil des Bildverarbeitungssystems sein.

317
00:49:22,000 --> 00:49:26,000
Wenn Sie in einem industriellen Umfeld sind, wird die Beleuchtung künstlich sein.

318
00:49:30,000 --> 00:49:34,000
Sie werden die Beleuchtung so aufbauen, dass sie ihr Problem möglichst einfach lösen kann.

319
00:49:40,000 --> 00:49:44,000
In natürlichen Szenen ist die Beleuchtung Teil der Szene.

320
00:49:44,000 --> 00:49:48,000
Wenn Sie draußen Aufnahmen machen, können Sie künstliche Beleuchtung hinzufügen.

321
00:49:48,000 --> 00:49:52,000
Aber Sie kommen nicht drum herum, dass Ihnen auch noch das Tageslicht die Szene beleuchtet.

322
00:49:56,000 --> 00:50:00,000
Die heutigen Sensoren sind digital.

323
00:50:00,000 --> 00:50:04,000
Sie liefern Ihnen ein digitales Bild.

324
00:50:04,000 --> 00:50:08,000
Das heißt, das Bild ist örtlich diskretisiert.

325
00:50:08,000 --> 00:50:12,000
Wir haben die einzelnen Bildpunkte.

326
00:50:12,000 --> 00:50:16,000
Jeder Bildpunkt ist in seiner Amplitude diskretisiert.

327
00:50:16,000 --> 00:50:20,000
Wir haben an dieser Stelle digitale Informationen.

328
00:50:20,000 --> 00:50:24,000
Die geht in einen Computer.

329
00:50:24,000 --> 00:50:28,000
Auf dem Computer läuft ein Betriebssystem.

330
00:50:28,000 --> 00:50:32,000
Im Rahmen dieser Vorlesung laufen die Bildverarbeitungsalgorithmen.

331
00:50:32,000 --> 00:50:36,000
Daraus kommt das, was wir wissen wollen.

332
00:50:36,000 --> 00:50:40,000
Das ist ganz allgemein ein Bildverarbeitungssystem.

333
00:50:46,000 --> 00:50:50,000
Wenn wir jetzt Bildverarbeitung in der Praxis einsetzen wollen,

334
00:50:50,000 --> 00:50:54,000
brauchen Sie typischerweise Wissen aus dem Anwendungsgebiet.

335
00:50:54,000 --> 00:50:58,000
Also wenn Sie medizinische Bildverarbeitung betreiben wollen,

336
00:50:58,000 --> 00:51:02,000
dann kann man Ihnen natürlich irgendwelche medizinischen Bilder zeigen.

337
00:51:02,000 --> 00:51:06,000
Aber man weiß nicht, was da zu sehen ist.

338
00:51:06,000 --> 00:51:10,000
Und man weiß auch nicht, was man sehen will.

339
00:51:10,000 --> 00:51:14,000
Deswegen brauchen Sie Wissen aus dem Anwendungsgebiet.

340
00:51:14,000 --> 00:51:18,000
Und häufig ist es so,

341
00:51:18,000 --> 00:51:22,000
mit der Bildverarbeitung lösen Sie nicht irgendwelche Probleme,

342
00:51:22,000 --> 00:51:26,000
die noch nie gelöst wurden, sondern Sie wollen irgendwelche Probleme,

343
00:51:26,000 --> 00:51:30,000
die gelöst wurden, automatisch lösen.

344
00:51:30,000 --> 00:51:34,000
Die Methoden und Verfahren aus diesen wissenschaftlichen Disziplinen

345
00:51:34,000 --> 00:51:38,000
sollte man auch kennen, liefern einen Anhaltspunkt dafür,

346
00:51:38,000 --> 00:51:42,000
wie man dann vielleicht an das Problem mit Bildverarbeitungsalgorithmen

347
00:51:42,000 --> 00:51:46,000
umgeht. Im Kern der Bildverarbeitung sehen wir die drei Disziplinen Computer Vision,

348
00:51:46,000 --> 00:51:50,000
Machine Vision, Image Processing.

349
00:51:50,000 --> 00:51:54,000
Wissen, das man aus den Anwendungsgebieten haben sollte,

350
00:51:54,000 --> 00:51:58,000
ist das, was wir drumherum sehen.

351
00:51:58,000 --> 00:52:02,000
Mathematik hilft immer.

352
00:52:02,000 --> 00:52:06,000
Sei es, dass Sie Optimierungsverfahren benötigen,

353
00:52:06,000 --> 00:52:10,000
sei es, dass Sie

354
00:52:10,000 --> 00:52:14,000
irgendwelche Messfehler in Ihren Daten haben,

355
00:52:14,000 --> 00:52:18,000
dann wollen Sie mit der Statistik versuchen, die in den Griff zu kriegen,

356
00:52:18,000 --> 00:52:22,000
die richtigen Werte zu schätzen.

357
00:52:22,000 --> 00:52:26,000
Sie wollen vielleicht wissen, mit Methoden des Machine Learnings,

358
00:52:26,000 --> 00:52:30,000
wie kommt man dazu, irgendwelche höherwertigen Informationen zu extrahieren.

359
00:52:30,000 --> 00:52:34,000
Methoden des maschinellen Sehens,

360
00:52:34,000 --> 00:52:38,000
wenn Sie das mit neuronalen Netzen machen,

361
00:52:38,000 --> 00:52:42,000
wird das auch gerne als KI-Methoden bezeichnet.

362
00:52:42,000 --> 00:52:46,000
Sie müssen das gar nicht so hoch aufhängen wie neuronale Netze.

363
00:52:46,000 --> 00:52:50,000
Sie können auch Methoden nehmen, die es schon lange gibt,

364
00:52:50,000 --> 00:52:54,000
Support-Vector-Maschinen, um irgendwelche Bilder zu segmentieren.

365
00:52:54,000 --> 00:52:58,000
Das sind alles Verfahren der künstlichen Intelligenz.

366
00:52:58,000 --> 00:53:02,000
Wenn Sie Roboter steuern wollen, müssen Sie natürlich auch noch

367
00:53:02,000 --> 00:53:06,000
nicht nur die Bilder verstehen, die der Roboter gerade sieht,

368
00:53:06,000 --> 00:53:10,000
die man so einem Roboter kontrollieren kann.

369
00:53:10,000 --> 00:53:14,000
Die ganze Kontrolltheorie müssen Sie kennen.

370
00:53:14,000 --> 00:53:18,000
Wenn Sie Bilder zum Beispiel vom Rauschen befreien wollen,

371
00:53:18,000 --> 00:53:22,000
dann sind das ganz klassische Signalverarbeitungsaufgaben.

372
00:53:22,000 --> 00:53:26,000
Digitale Signalverarbeitung ist ein Thema,

373
00:53:26,000 --> 00:53:30,000
was man auch braucht.

374
00:53:30,000 --> 00:53:34,000
Bei Bildern wird die digitale Signalverarbeitung

375
00:53:34,000 --> 00:53:38,000
einfacher genutzt, als sie vielleicht bei Audiosignalen ist.

376
00:53:38,000 --> 00:53:42,000
Bei Audiosignalen haben Sie vielleicht

377
00:53:42,000 --> 00:53:46,000
einen Megabit pro Sekunde, was da zu verarbeiten ist.

378
00:53:46,000 --> 00:53:50,000
Bei einer Kamera haben Sie gerne einen Gigabit pro Sekunde

379
00:53:50,000 --> 00:53:54,000
und mehr, was Sie verarbeiten müssen.

380
00:53:54,000 --> 00:53:58,000
Das bedeutet, die Filter, die Sie da laufen lassen können,

381
00:53:58,000 --> 00:54:02,000
und das ist ja das, was Signalverarbeitung ist, dürfen nicht so komplex sein.

382
00:54:02,000 --> 00:54:06,000
Was aber, anders als in der digitalen Signalverarbeitung,

383
00:54:06,000 --> 00:54:10,000
die Sie wahrscheinlich schon gehört haben,

384
00:54:10,000 --> 00:54:14,000
wenn nicht, sollten Sie es hören, gelernt haben,

385
00:54:14,000 --> 00:54:18,000
ist bei der Bildverarbeitung die nicht-lineare Signalverarbeitung

386
00:54:18,000 --> 00:54:22,000
ein wesentliches Element.

387
00:54:22,000 --> 00:54:26,000
Wenn Sie 3D-Geometrie erfassen wollen,

388
00:54:26,000 --> 00:54:30,000
ist es definitiv gut, wenn man weiß, wie die Optik funktioniert,

389
00:54:30,000 --> 00:54:34,000
wie die Bilder aus dem 3D-Raum auf ein Bild abgebildet werden.

390
00:54:34,000 --> 00:54:38,000
Dann ist es natürlich auch immer hilfreich,

391
00:54:38,000 --> 00:54:42,000
wenn man weiß, wie der Vorgang der Bildaufnahme,

392
00:54:42,000 --> 00:54:46,000
also wie so ein Sensor funktioniert.

393
00:54:46,000 --> 00:54:50,000
Zusammen mit der Physik kann man dann auch so einen Sensor kalibrieren,

394
00:54:50,000 --> 00:54:54,000
damit Sie dann in den Bildern auch messen.

395
00:54:54,000 --> 00:54:58,000
Also insgesamt ein ganz spannendes Thema,

396
00:54:58,000 --> 00:55:02,000
dass Sie letztendlich sinnvolle Bildverarbeitung nur machen können,

397
00:55:02,000 --> 00:55:06,000
wenn Sie auch die Anwendungsgebiete kennen, oder anders gesprochen,

398
00:55:06,000 --> 00:55:10,000
wenn Sie wissen, wie man Bildverarbeitung macht.

399
00:55:10,000 --> 00:55:14,000
Dann haben Sie einen Werkzeugkasten in der Hand,

400
00:55:14,000 --> 00:55:18,000
mit dem Sie in viele Anwendungsgebiete gehen können,

401
00:55:18,000 --> 00:55:22,000
die Sie vielleicht mal gerade interessieren,

402
00:55:22,000 --> 00:55:26,000
und dort können Sie etwas Sinnvolles mit Ihrem Werkzeugkasten machen.

403
00:55:26,000 --> 00:55:30,000
Das war die Auswertung von Sternenbildern.

404
00:55:34,000 --> 00:55:38,000
So viel zum Überblick.

405
00:55:38,000 --> 00:55:42,000
Wir werden

406
00:55:42,000 --> 00:55:46,000
nun mit den Grundlagen der Bilderpassung und der Repräsentation beschäftigen.

407
00:55:46,000 --> 00:55:50,000
Dann gibt es Einführung

408
00:55:50,000 --> 00:55:54,000
in die Bildverarbeitung,

409
00:55:54,000 --> 00:55:58,000
was für Operatoren gibt es, was für Operationen.

410
00:55:58,000 --> 00:56:02,000
Sie sehen hier, es gibt Punkt-Operationen, die werden auf einzelnen Bildpunkten ausgeführt.

411
00:56:02,000 --> 00:56:06,000
Lokale, globale Operationen, also es gibt Algorithmen,

412
00:56:06,000 --> 00:56:10,000
die definitiv zur Bildverarbeitung gehören, die eine lokale Umgebung

413
00:56:10,000 --> 00:56:14,000
in einem Bildpunkt berücksichtigen, um zu einem Ergebnis zu kommen.

414
00:56:14,000 --> 00:56:18,000
Das wäre eine Faltung zum Beispiel, oder die das ganze Bild berücksichtigen,

415
00:56:18,000 --> 00:56:22,000
wenn Sie eine Transformation machen.

416
00:56:22,000 --> 00:56:26,000
Sie können natürlich Filter ableiten, da gibt es Tiefpassfilter, Hochpassfilter,

417
00:56:26,000 --> 00:56:30,000
es gibt aber auch nicht lineare Filter, Medienfilter zum Beispiel,

418
00:56:30,000 --> 00:56:34,000
und geometrische Transformationen.

419
00:56:34,000 --> 00:56:38,000
Wir werden dann das Bild als Signal

420
00:56:38,000 --> 00:56:42,000
uns anschauen und

421
00:56:42,000 --> 00:56:46,000
damit digitale Signalverarbeitung machen. Sie erkennen schon

422
00:56:46,000 --> 00:56:50,000
Foyer-Transformationen, das ist definitiv digitale Signalverarbeitung, Filterung und Faltung.

423
00:56:50,000 --> 00:56:54,000
Sie sind letztendlich auch das, was unter drei als Operationen kommt,

424
00:56:54,000 --> 00:56:58,000
darstellbar als Operationen, aber eben dann

425
00:56:58,000 --> 00:57:02,000
unter dem Aspekt, dass wir das Signal filtern wollen.

426
00:57:02,000 --> 00:57:06,000
Verschiedene Filter werden wir uns anschauen,

427
00:57:06,000 --> 00:57:10,000
sowohl im Ortsbereich als auch im Frequenzbereich.

428
00:57:10,000 --> 00:57:14,000
Neben der Foyer-Transformation gibt es auch andere Transformationen,

429
00:57:14,000 --> 00:57:18,000
die Sie hier sehen, die teilweise besondere Eigenschaften haben.

430
00:57:18,000 --> 00:57:22,000
Teilweise aber auch schlechter sind als die Foyer-Transformationen,

431
00:57:22,000 --> 00:57:26,000
schlechter im Sinne von Frequenzauflösung,

432
00:57:26,000 --> 00:57:30,000
aber einen Bildpunkt haben Sie ja immer viele,

433
00:57:30,000 --> 00:57:34,000
die sich viel, viel schneller rechnen lassen.

434
00:57:34,000 --> 00:57:38,000
Und dann stellt sich natürlich auch noch die Frage Kameras.

435
00:57:38,000 --> 00:57:42,000
Da gibt es dann die 50 Megapixel-Kamera,

436
00:57:42,000 --> 00:57:46,000
es gibt auch gar kein Display, auf dem Sie das darstellen können.

437
00:57:46,000 --> 00:57:50,000
Da brauchen Sie das Bild in dieser hohen Auflösung.

438
00:57:50,000 --> 00:57:54,000
Da können Sie nicht in einem kleineren Bild,

439
00:57:54,000 --> 00:57:58,000
also das große Bild, machen Sie immer kleiner, erzeugen Sie eine Bildpyramide,

440
00:57:58,000 --> 00:58:02,000
können Sie da nicht vielleicht genauso viel mit anfangen.

441
00:58:02,000 --> 00:58:06,000
Wir werden uns kurz mit Farbe beschäftigen

442
00:58:06,000 --> 00:58:10,000
und dann mit der niederschwelligen

443
00:58:10,000 --> 00:58:14,000
Bildanalyse. Bildsegmentierung,

444
00:58:14,000 --> 00:58:18,000
Suche nach geometrischen Primitiven,

445
00:58:18,000 --> 00:58:22,000
also die schon erwähnten Linienkantenkreise.

446
00:58:28,000 --> 00:58:32,000
In der Übung und auch im Laborversuch

447
00:58:32,000 --> 00:58:36,000
ist es uns wichtig, dass Sie auch etwas Erfahrung mit der Bildverarbeitung sammeln.

448
00:58:36,000 --> 00:58:40,000
Ich kann Ihnen so viel erzählen, wie ich will,

449
00:58:40,000 --> 00:58:44,000
im Sinne von,

450
00:58:44,000 --> 00:58:48,000
ich will jetzt hier dieses Buch

451
00:58:48,000 --> 00:58:52,000
Digital Character Animation in dem Regal detektieren.

452
00:58:52,000 --> 00:58:56,000
Ich kann Ihnen so viel erzählen, wie ich will, dass das eine schwierige Aufgabe ist.

453
00:58:56,000 --> 00:59:00,000
Das werden Sie nicht verinnerlichen,

454
00:59:00,000 --> 00:59:04,000
weil Sie als Mensch, naja, wir greifen Sie da rein und

455
00:59:04,000 --> 00:59:08,000
haben das Buch.

456
00:59:08,000 --> 00:59:12,000
Da ist es uns deswegen wichtig, dass Sie praktische Erfahrungen liefern.

457
00:59:12,000 --> 00:59:16,000
Es wird also im Rahmen der Übung und auch des Laborversuchs mit Bildern gearbeitet.

458
00:59:16,000 --> 00:59:20,000
Wir erwarten von Ihnen dann, dass Sie da einfache Programme schreiben,

459
00:59:20,000 --> 00:59:24,000
um einfach mal Informationen aus Bildern rauszuholen.

460
00:59:24,000 --> 00:59:28,000
Nun kann man das in Matlab machen, haben wir ja lange gemacht,

461
00:59:28,000 --> 00:59:32,000
oder der kostenlosen Version von Matlab mit Gnu Octave.

462
00:59:32,000 --> 00:59:36,000
Jetzt machen wir das aber mit Python, weil das eben das ist, wo Sie im Internet die meisten Bibliotheken mittlerweile finden.

463
00:59:36,000 --> 00:59:40,000
Für alle möglichen Anwendungen, nicht nur in der Bildverarbeitung.

464
00:59:40,000 --> 00:59:44,000
Die ganzen maschinellen Lernmethoden sind auch in Python

465
00:59:44,000 --> 00:59:48,000
verfügbar. Es ist einfach gut, dass Sie das

466
00:59:48,000 --> 00:59:52,000
da nutzen können und dann mithilfe der Bibliotheken auch einfache Bildverarbeitungsaufgaben

467
00:59:52,000 --> 00:59:56,000
lösen. Python ist nur

468
00:59:56,000 --> 01:00:00,000
eine Programmiersprache, aber dann finden Sie im Netz

469
01:00:00,000 --> 01:00:04,000
auch viele Bibliotheken, die schon spezielle

470
01:00:04,000 --> 01:00:08,000
Bildverarbeitungsroutinen implementieren.

471
01:00:08,000 --> 01:00:12,000
Wir haben hier den Anspruch, dass Sie für viele

472
01:00:12,000 --> 01:00:16,000
Bildverarbeitungsroutinen wissen, wie sie funktionieren.

473
01:00:16,000 --> 01:00:20,000
Wenn Sie aber später ein Problem lösen wollen,

474
01:00:20,000 --> 01:00:24,000
dann ist die Empfehlung immer, schauen Sie, ob es nicht vielleicht schon eine

475
01:00:24,000 --> 01:00:28,000
sinnvolle Implementierung der Algorithmen gibt, die Sie benötigen.

476
01:00:28,000 --> 01:00:32,000
Dann greifen Sie auch Bibliotheken und Bibliotheken zu.

477
01:00:32,000 --> 01:00:36,000
Eine Bibliothek, die sich da sehr verbreitet hat, ist OpenCV,

478
01:00:36,000 --> 01:00:40,000
die sich mit einfachen Methoden der Bildverarbeitung

479
01:00:40,000 --> 01:00:44,000
beschäftigt, weil die mit Algorithmen zur Verfügung stellt,

480
01:00:44,000 --> 01:00:48,000
zur Bildfilterung, aber auch zur Bildanalyse

481
01:00:48,000 --> 01:00:52,000
und auch durchaus

482
01:00:52,000 --> 01:00:56,000
höherwertigen Bildanalysen. Solche Bibliotheken gibt es

483
01:00:56,000 --> 01:01:00,000
viel. Denken Sie daran, nur weil es im Internet

484
01:01:00,000 --> 01:01:04,000
herunterladbar ist, ist die Nutzung nicht unbedingt

485
01:01:04,000 --> 01:01:08,000
kostenlos. Die meiste Software, die Sie

486
01:01:08,000 --> 01:01:12,000
im Internet herunterladen, hat irgendwelche Lizenzbedingungen

487
01:01:12,000 --> 01:01:16,000
und wenn Sie zu Hause für sich etwas programmieren wollen, dann müssen Sie das auch nicht weiter durchlesen.

488
01:01:16,000 --> 01:01:20,000
Aber wenn Sie das später im beruflichen Umfeld

489
01:01:20,000 --> 01:01:24,000
kommerziell nutzen wollen, müssen Sie genau hingucken. OpenCV zum Beispiel hat

490
01:01:24,000 --> 01:01:28,000
durchaus viele Algorithmen drin, die sind patentiert.

491
01:01:28,000 --> 01:01:32,000
Dann müssen Sie dem Patentinhaber Geld bezahlen, wenn Sie das für ein Produkt

492
01:01:32,000 --> 01:01:36,000
nutzen wollen. Andere Softwarebibliotheken, die Sie herunterladen,

493
01:01:36,000 --> 01:01:40,000
können Sie benutzen. Da steht aber drin, dass Sie,

494
01:01:40,000 --> 01:01:44,000
wenn Sie die benutzen, Ihren Code,

495
01:01:44,000 --> 01:01:48,000
mit dem Sie diese Software benutzen, auch veröffentlichen müssen.

496
01:01:48,000 --> 01:01:52,000
Das ist für manch ein Produkt akzeptabel.

497
01:01:52,000 --> 01:01:56,000
Für manch ein Produkt ist es nicht akzeptabel. Also achten Sie darauf.

498
01:01:56,000 --> 01:02:00,000
Hier gibt es eine ganze Menge von Literatur.

499
01:02:04,000 --> 01:02:08,000
Manches kann man einfach herunterladen.

500
01:02:08,000 --> 01:02:12,000
Manches können Sie kaufen.

501
01:02:12,000 --> 01:02:16,000
In der Bibliothek bekommen Sie das.

502
01:02:16,000 --> 01:02:20,000
Die Vorlesung oder die Prüfung

503
01:02:20,000 --> 01:02:24,000
sollten Sie auch handhaben können,

504
01:02:24,000 --> 01:02:28,000
ohne dass Sie sich diese Bücher kaufen.

505
01:02:28,000 --> 01:02:32,000
Aber wenn das Thema spannend ist, dann will man ja manchmal auch mehr wissen.

506
01:02:32,000 --> 01:02:36,000
Dann haben Sie hier eine Liste von Dingen, die Sie sich anschauen können.

507
01:02:40,000 --> 01:02:44,000
Okay, damit sind wir bei dem ersten Foliensatz durch.

508
01:02:54,000 --> 01:02:58,000
Heute

509
01:02:58,000 --> 01:03:02,000
hätte ich vielleicht auch sagen sollen,

510
01:03:02,000 --> 01:03:06,000
es gibt ja immer Vorlesungen und Übungen. Im Kalender steht das an einem Tag.

511
01:03:06,000 --> 01:03:10,000
Wir machen das so, dass Sie nur Vorlesungen oder nur Übungen bekommen.

512
01:03:10,000 --> 01:03:14,000
Heute gibt es zwei Stunden Vorlesung und

513
01:03:14,000 --> 01:03:18,000
dann eine Dreiviertelstunde Übung. Alles nur Vorlesungen.

514
01:03:18,000 --> 01:03:22,000
Von daher wäre jetzt ein guter Moment

515
01:03:22,000 --> 01:03:26,000
für eine Pause und wir machen dann um 9.35 Uhr weiter.

516
01:03:30,000 --> 01:03:34,000
Bis 9.35 Uhr schalte ich jetzt mal mein Mikrofon ab

517
01:03:34,000 --> 01:03:38,000
und dann sehen wir uns gleich wieder.

518
01:03:38,000 --> 01:03:42,000
Ich wünsche Ihnen viel Spaß an der Kaffeemaschine.

519
01:03:52,000 --> 01:03:56,000
Ich wünsche Ihnen viel Spaß an der Kaffeemaschine.

520
01:04:22,000 --> 01:04:26,000
Ich wünsche Ihnen viel Spaß an der Kaffeemaschine.

521
01:04:52,000 --> 01:04:56,000
Ich wünsche Ihnen viel Spaß an der Kaffeemaschine.

522
01:05:22,000 --> 01:05:26,000
Ich wünsche Ihnen viel Spaß an der Kaffeemaschine.

523
01:05:52,000 --> 01:05:56,000
Ich wünsche Ihnen viel Spaß an der Kaffeemaschine.

524
01:06:22,000 --> 01:06:26,000
Ich wünsche Ihnen viel Spaß an der Kaffeemaschine.

525
01:06:52,000 --> 01:06:56,000
Ich wünsche Ihnen viel Spaß an der Kaffeemaschine.

526
01:07:22,000 --> 01:07:26,000
Ich wünsche Ihnen viel Spaß an der Kaffeemaschine.

527
01:07:52,000 --> 01:07:56,000
Ich wünsche Ihnen viel Spaß an der Kaffeemaschine.

528
01:08:22,000 --> 01:08:26,000
Ich wünsche Ihnen viel Spaß an der Kaffeemaschine.

529
01:08:52,000 --> 01:08:56,000
Ich wünsche Ihnen viel Spaß an der Kaffeemaschine.

530
01:09:22,000 --> 01:09:26,000
Ich wünsche Ihnen viel Spaß an der Kaffeemaschine.

531
01:09:52,000 --> 01:09:56,000
Ja, kommen wir zurück.

532
01:09:56,000 --> 01:10:00,000
Ja, kommen wir zurück.

533
01:10:00,000 --> 01:10:04,000
Ja, kommen wir zurück.

534
01:10:04,000 --> 01:10:08,000
Jetzt beschäftigen wir uns einmal mit dem digitalen Bild

535
01:10:08,000 --> 01:10:12,000
und also als Pendant dafür, wie funktioniert das Auge.

536
01:10:12,000 --> 01:10:16,000
und also als Pendant dazu, wie funktioniert das Auge.

537
01:10:16,000 --> 01:10:28,800
Wir nehmen Helligkeit wahr, gibt es den Begriff der Intensität. Physikalisch ist das die Energie

538
01:10:28,800 --> 01:10:33,040
des eingefallenen Lichts pro Fläche und Zeit.

539
01:10:33,040 --> 01:10:48,880
Das ist die Intensität. Was nehmen wir wahr? Wir nehmen die Helligkeit wahr. Mit zunehmender

540
01:10:48,880 --> 01:11:01,480
Intensität des Lichtes nehmen wir das Licht als heller wahr. Ganz wichtig, Intensität ist etwas

541
01:11:01,480 --> 01:11:10,680
Physikalisches. Helligkeit ist das, was wir wahrnehmen. Da besteht ein Zusammenhang, würde

542
01:11:10,680 --> 01:11:19,400
behaupten ein monotoner Zusammenhang. Solange wir uns in einem Intensitätsbereich befinden,

543
01:11:19,400 --> 01:11:25,800
den das menschliche Auge noch einigermaßen ordentlich wahrnehmen kann, natürlich zwischen

544
01:11:25,800 --> 01:11:30,600
sehr sehr dunkel und sehr sehr sehr sehr dunkel, sehen wir nichts, können wir da nicht mehr

545
01:11:30,600 --> 01:11:35,320
unterscheiden. Und wenn es irgendwann zu hell ist für das Auge, dann hilft es auch nicht,

546
01:11:35,320 --> 01:11:40,040
wenn die Intensität weiter zunimmt. Die Helligkeit nimmt nicht zu. Aber in diesem

547
01:11:40,040 --> 01:11:45,960
großen Intervall, wo wir Helligkeiten unterscheiden können oder Intensitäten unterscheiden können,

548
01:11:45,960 --> 01:11:54,120
gibt es da letztendlich einen monotonen Zusammenhang. Aber der Zusammenhang ist nicht linear.

549
01:11:55,800 --> 01:12:07,640
Heißt also, eine Intensitätsverdoppelung zieht nicht unbedingt eine Verdoppelung der

550
01:12:07,640 --> 01:12:22,080
subjektiv wahrgenommenen Helligkeit nach sich. Das Sehen, das menschliche Sehen orientiert sich

551
01:12:22,080 --> 01:12:33,240
am Kontext. Helles Grau, mittleres Grau, dunkles Grau. Aber wenn Sie jetzt messen würden,

552
01:12:33,240 --> 01:12:42,240
sind diese drei Grautöne alle gleich. Die nehmen Sie aber unterschiedlich wahr aufgrund des Kontexts,

553
01:12:42,240 --> 01:12:53,520
aufgrund der Umgebung. Wir fallen auch gerne darauf rein, dass es irgendwelche Illusionen

554
01:12:53,520 --> 01:13:03,480
gibt. Wir glauben, dass hier unterschiedliche Grauwerte sind. Aber das muss dann aufgrund

555
01:13:03,640 --> 01:13:07,600
des Schattens, den wir uns wegrechnen, nicht unbedingt der Fall sein.

556
01:13:07,600 --> 01:13:20,520
Möglich sehen Sie irgendetwas, was sich hier dreht. Das ist ein Bild, da bewegt sich gar nichts.

557
01:13:20,520 --> 01:13:42,720
Wir sind auch leicht durch Illusionen in die Irre zu führen, weil wir gewisse Voraussetzungen sehen,

558
01:13:42,720 --> 01:13:48,960
wie muss ein Bild angeordnet sein. Augen unten, Mund oben. Dieses Bild kennen Sie

559
01:13:48,960 --> 01:14:08,000
als Fetcher-Illusion. Das ist die ehemalige amerikanische First Wife. Das menschliche Auge,

560
01:14:08,000 --> 01:14:16,760
kommen wir jetzt mal weg von irgendwelchen Spaßsachen, ist letztendlich eine Kamera.

561
01:14:22,200 --> 01:14:31,240
Wir haben die Iris, das ist letztendlich ein Muskel, mit dem wird die Pupille, die Blende,

562
01:14:31,240 --> 01:14:41,680
das Loch kontrolliert. Wir können das Loch klein machen, wir können das Loch groß machen.

563
01:14:45,680 --> 01:14:58,600
Licht kommt hier rein, geht durch die Linse und von der Linse ist mehr oder weniger sichtbar,

564
01:14:58,600 --> 01:15:06,600
abhängig davon, wie groß unsere Pupille ist. Und dann fällt das Licht hier auf die Netzhaut.

565
01:15:10,160 --> 01:15:17,320
Denn auf der Netzhaut sind Nervenenden, die reagieren auf die Energie des Lichts.

566
01:15:19,320 --> 01:15:24,000
Und die Nerven gehen dann zusammen in dem optischen Nerv ins Gehirn.

567
01:15:28,600 --> 01:15:47,520
Wir haben im Auge Zapfen, die sind für die Farbwahrnehmung zuständig. Wir haben Stäbchen,

568
01:15:47,520 --> 01:15:54,920
englischen Rods, die sind für die Helligkeitswahrnehmung zuständig.

569
01:15:58,640 --> 01:16:04,920
Hier sehen sie die Aussehung, ist letztendlich für uns weniger interessant als für die Biologen.

570
01:16:09,360 --> 01:16:15,800
Was an diesem Bild vielleicht noch interessant ist, die Frage, wo kommt das Licht her?

571
01:16:17,800 --> 01:16:26,040
Wir haben hier Zapfen, Stäbchen, hier oben sind die Nerven. Das Licht kommt von hier.

572
01:16:27,920 --> 01:16:33,280
Licht muss also letztendlich zwischen den Nervenbahnen durch und dann kommt es auf diese Zellen.

573
01:16:34,920 --> 01:16:40,600
Wir haben etwa sechs Millionen Zäpfchen, wir haben hundert Millionen Stäbchen.

574
01:16:41,600 --> 01:16:46,600
Das heißt, Stäbchen können wir, das muss nicht so sein, aber ist so, können wir viel mehr sehen.

575
01:16:46,600 --> 01:16:54,440
Stäbchen sind sehr empfindlich, sie nehmen nur eine Helligkeit wahr oder eine Intensität,

576
01:16:54,440 --> 01:17:00,760
liefern also letztendlich ein Schwarz-Weiß-Bild, das Sehen bei Nacht. Das machen die Stäbchen.

577
01:17:00,760 --> 01:17:09,480
Nachts, wenn sie irgendwo mitten im Licht sind, können sie bei klarem Himmel in die Sterne schauen.

578
01:17:09,880 --> 01:17:15,480
Die Sterne sind weiß, im Himmel schwarz. So nehmen wir es wahr.

579
01:17:15,480 --> 01:17:21,720
Und dann gibt es ja die Fotos von den Astronomen, da sind die Sterne bunt.

580
01:17:24,280 --> 01:17:29,040
Das kann zwei Gründe haben. Das eine ist, manchmal nehmen die Astronomen

581
01:17:29,040 --> 01:17:36,200
irgendwelche Sterne und malen sie bunt an, aber viele Sterne leuchten auch farbig.

582
01:17:37,200 --> 01:17:44,680
Nur die Intensität ist so schwach, dass wir das nachts, nur nachts können wir die Sterne ja überhaupt sehen,

583
01:17:44,680 --> 01:17:50,680
dass wir da die Farbe nicht wahrnehmen können, weil unsere Zapfen nicht empfindlich genug sind.

584
01:17:50,680 --> 01:17:56,320
Sie sind weniger sensibil. Deswegen nehmen wir die Sterne als schwarz-weiß wahr, also in Graustufen.

585
01:17:56,320 --> 01:18:11,320
Diese Nervenzellen sind jetzt helligkeitsempfindlich. Dann ist noch die Frage, was ist die örtliche Auflösung?

586
01:18:11,320 --> 01:18:19,320
Wie nah können Objekte beieinander sein, damit wir sie noch voneinander trennen können?

587
01:18:19,320 --> 01:18:23,320
Sie können sich das auch anders vorstellen. Sie können ein Schachbrett nehmen.

588
01:18:23,320 --> 01:18:30,320
Nicht groß müssen die Kästchen sein, damit sie noch sehen können, dass das ein Schachbrettmuster ist und nicht einfach eine graue Fläche.

589
01:18:30,320 --> 01:18:41,320
Mein Anzug erscheint wahrscheinlich bei Ihnen blau. Wenn ich das Ding jetzt ausziehen würde und immer dichter an die Kamera ranhalten würde,

590
01:18:41,320 --> 01:18:46,320
würden Sie irgendwann erkennen, da sind einzelne Fadenstrukturen. Der ist nicht ganz glatt blau, so wie Sie ihn sehen.

591
01:18:46,320 --> 01:18:53,320
Genauso ist es auch mit dem Schachbrettmuster. Wenn Sie ein Schachbrett haben und gehen immer weiter weg, sehen Sie irgendwann nur noch eine graue Fläche.

592
01:18:53,320 --> 01:19:02,320
Die örtliche Auflösung, die man trennen kann, liegt irgendwo bei 0,5 bis 2 Winkelminuten.

593
01:19:02,320 --> 01:19:07,320
Letztendlich hängt das vom Winkel ab und nicht von der absoluten Entfernung.

594
01:19:07,320 --> 01:19:16,320
Die Entfernung beeinflusst dann auch die Größe, was Sie auseinander trennen können. Der Winkel ist unabhängig.

595
01:19:16,320 --> 01:19:27,320
Wenn Sie jetzt wissen wollen, was eine Winkelminute ist, also wenn Sie ein Objekt 5 Meter entfernt haben, dann können Sie 1,5 Millimeter noch voneinander trennen.

596
01:19:27,320 --> 01:19:34,320
Das ist dann eine Winkelminute und das ist dann im Rahmen dessen, was viele Menschen hinkriegen.

597
01:19:34,320 --> 01:19:44,320
Örtliche Auflösung 0,5 bis 2 Winkelminuten. Na ja, der eine kann besser gucken als der andere. Das hat auch nicht unbedingt immer etwas mit der Brille zu tun, sondern einfach auch mit der Realisierung Ihres Auges.

598
01:19:44,320 --> 01:19:59,320
Wo sind denn diese Stäbchen und Zäpfchen?

599
01:19:59,320 --> 01:20:06,320
Hier hatte ich ja das Rote eingezeichnet. Hier sind sie überall verteilt.

600
01:20:06,320 --> 01:20:17,320
Wenn Sie darauf achten, wie Sie gucken, dann werden Sie merken, dass Sie sehr viel sehen. Sie haben ein Blickwinkel von über 180 Grad.

601
01:20:17,320 --> 01:20:23,320
Aber wenn Sie jetzt irgendwie was lesen wollen, was da ist, dann gucken Sie dahin. Warum gucken Sie dahin?

602
01:20:23,320 --> 01:20:27,320
Weil Sie am Rande Ihres Blickfeldes letztendlich nicht scharf gucken können.

603
01:20:27,320 --> 01:20:35,320
Daraus können wir dann auch schon schließen, dass am Rande des Blickfeldes die Dichte der Stäbchen und Zäpfchen nicht besonders groß ist.

604
01:20:35,320 --> 01:20:50,320
Das ist hier jetzt einfach mal aufgezeichnet. Wir haben nach oben aufgezeichnet die Zahl der lichtempfindlichen Nervenzellen pro Quadratmillimeter.

605
01:20:50,320 --> 01:21:10,320
Hier haben wir den Abstand von der visuellen Achse. Dann gibt es eine Häufung dieser Zellen in einem relativ kleinen Winkel von plus minus 20 Grad von der Mitte Ihres Auges.

606
01:21:10,320 --> 01:21:32,320
Dann gibt es auch noch einen Punkt, da können Sie gar nichts sehen. Das ist der Punkt, wo die Nerven von den ganzen Zellen im optischen Sehnerv ins Gehirn gehen.

607
01:21:32,320 --> 01:21:36,320
Da ist dann kein Platz mehr für die lichtempfindlichen Zellen.

608
01:21:41,320 --> 01:21:52,320
Für die Cones sehen Sie, die sind hier nur ganz eng um die visuelle Achse verteilt. Ansonsten haben wir hier nur eine Grundwahrnehmung der Farbe.

609
01:21:52,320 --> 01:22:03,320
Die Rods sind etwas breiter verteilt und ermöglichen das periphere Sehen.

610
01:22:11,320 --> 01:22:30,320
Vorhin hatte ich gesagt, wir sehen im Kontext und ein Gesetz, eine Beobachtung, das weberische oder weber-fechnerische Gesetz beschreibt das.

611
01:22:30,320 --> 01:22:37,320
Stellen Sie sich vor, wir haben ein graues Bild, die Helligkeit I.

612
01:22:37,320 --> 01:22:45,320
Hier haben wir jetzt einen Fleck, der hat eine andere Helligkeit, ein I plus Delta I.

613
01:22:45,320 --> 01:22:52,320
Wie groß muss dieses Delta sein, damit Sie es sehen können?

614
01:22:52,320 --> 01:23:00,320
Damit Sie diesen Kreis von dem Hintergrund unterscheiden können.

615
01:23:01,320 --> 01:23:14,320
Das weber-fechnerische Gesetz sagt, dieses Delta I zu I ist entscheidend für die Antwort auf die Frage, können Sie das sehen oder nicht.

616
01:23:14,320 --> 01:23:29,320
Da das Delta in Bezug genommen wird auf die Hintergrundhelligkeit, haben wir dann auch diesen Kontext in diesem Zusammenhang schon gesehen.

617
01:23:30,320 --> 01:23:38,320
Hier haben wir das mal aufgeteilt, den Rhythmus von Delta I zu I.

618
01:23:38,320 --> 01:23:48,320
Können Sie den Kreis leicht erkennen oder schlecht erkennen, das kann man als binäres Verhältnis natürlich darstellen.

619
01:23:48,320 --> 01:23:55,320
Aber letztendlich sehen Sie auch manchmal Dinge, wo Sie glauben, Sie sehen noch nichts.

620
01:23:56,320 --> 01:24:05,320
Deswegen ist diese Darstellung hier, man kann den Kreis vom Hintergrund gut trennen, man kann ihn schlecht trennen, durchaus sinnvoll.

621
01:24:05,320 --> 01:24:14,320
Ich habe mal an subjektiven Experimenten teilgenommen, da ging es letztendlich auch darum, können Sie etwas sehen oder nicht.

622
01:24:14,320 --> 01:24:25,320
Wir hatten da Grauwertbalken, also ein Bild, das war grau und dann war da in der Mitte ein dunkler Balken davor.

623
01:24:25,320 --> 01:24:31,320
Im definierten Abstand vor diesem dunkelgrauen Übergang rauschte das Bild.

624
01:24:31,320 --> 01:24:35,320
Dann war die Frage, können Sie das rauschen sehen oder nicht.

625
01:24:35,320 --> 01:24:39,320
Und man musste sich entscheiden, entweder man sah es oder man sah es nicht.

626
01:24:39,320 --> 01:24:43,320
Die Antwort, weiß ich nicht, gab es nicht.

627
01:24:43,320 --> 01:24:55,320
Und es war so, dass wir häufig dann letztendlich richtig geraten haben, obwohl wir der Meinung waren, eigentlich sehen wir da nichts mehr.

628
01:24:55,320 --> 01:25:01,320
Also unterschwellig sehen wir durchaus noch Dinge, die im Bewusstsein nicht so durchkommen.

629
01:25:01,320 --> 01:25:04,320
Aber wenn man sich dann zu der Entscheidung zwingt, dann sieht man doch was.

630
01:25:04,320 --> 01:25:08,320
Und dann sind wir hier eben bei dieser nicht-binären Skala.

631
01:25:08,320 --> 01:25:21,320
Und abhängig davon, ob wir jetzt mit Stäbchen oder Zäpfchen gucken, also mit Farbe oder nicht-Farbe, ist dieses Verhältnis Delta-I zu I, ab dem man da den Unterschied sehen kann, letztendlich leicht anders.

632
01:25:21,320 --> 01:25:31,320
Aber prinzipiell kann man da sehen, dass Sie abhängig von der Helligkeit unterschiedliche Delta-I haben.

633
01:25:31,320 --> 01:25:34,320
Das können Sie gegebenenfalls auch durch Graden approximieren.

634
01:25:34,320 --> 01:25:37,320
Dann haben Sie das Weber-Fechner-Gesetz.

635
01:25:44,320 --> 01:25:50,320
Also das Weber-Fechner-Gesetz ist etwas, was unser Gehirn irgendwie macht.

636
01:25:50,320 --> 01:25:58,320
Die Kombination aus Auge und Gehirn, das ist sicherlich etwas, was Sie mit einem Kamerasensor nicht haben werden.

637
01:25:58,320 --> 01:26:04,320
Der wird pro Bildpunkt irgendwie die Energie messen, die Intensität, die da kommt, aber nicht die Helligkeit.

638
01:26:15,320 --> 01:26:18,320
Hier haben wir ein Graustufenbild.

639
01:26:18,320 --> 01:26:26,320
Ich weiß jetzt nicht, wie Sie das sehen, aber ich kann Ihnen ja mal erzählen, was ich sehe.

640
01:26:26,320 --> 01:26:29,320
Ich schaue mir jetzt mal diesen Balken hier an.

641
01:26:31,320 --> 01:26:34,320
Der hat Grau.

642
01:26:34,320 --> 01:26:41,320
Der ist aber an dieser Seite heller als das Grau in der Mitte des Balkens.

643
01:26:41,320 --> 01:26:47,320
Und an dieser Stelle ist er dunkler als in der Mitte des Balkens.

644
01:26:47,320 --> 01:26:50,320
So nehme ich das wahr.

645
01:26:50,320 --> 01:26:53,320
Und so sollten Sie es aussehen.

646
01:26:53,320 --> 01:26:59,320
Was das Bildsignal aber ist, ist das, was wir hier sehen.

647
01:26:59,320 --> 01:27:02,320
Dann gibt es genau diese diskreten Stufen.

648
01:27:02,320 --> 01:27:05,320
Das heißt, diese Stufe hier ist einheitlich Grau.

649
01:27:05,320 --> 01:27:14,320
Unser Auge hat aber in der Verschaltung der verschiedenen Stäbchen und Zäpfchen,

650
01:27:15,320 --> 01:27:26,320
Jedes Zäpfchen geht nicht nur in das Gehirn, sondern jedes Stäbchen ist auch mit benachbarten Stäbchen verbunden.

651
01:27:26,320 --> 01:27:30,320
Dadurch beeinflussen sie sich gegenseitig und da ist ein Hochpasswert drin.

652
01:27:30,320 --> 01:27:35,320
Und wenn Sie diese Treppenstufen durch einen Hochpassfilter stecken würden,

653
01:27:35,320 --> 01:27:39,320
dann würden Sie eben genau diese Effekte kriegen, die ich da gerade beschrieben habe.

654
01:27:40,320 --> 01:27:47,320
Das heißt, unser Auge sorgt dafür, dass wir letztendlich eine Kontrastverstärkung vornehmen.

655
01:27:47,320 --> 01:28:00,320
Dann kann man sich natürlich noch die Frage stellen, wo wird das, was die Augen aufnehmen, im Gehirn verarbeitet.

656
01:28:00,320 --> 01:28:07,320
Das ist dann aber vielleicht mehr für die Biologen interessant als für uns.

657
01:28:07,320 --> 01:28:13,320
Die Augen sind so überkreuz verschaltet.

658
01:28:21,320 --> 01:28:27,320
Was für Signalverarbeitung gibt es im Auge?

659
01:28:27,320 --> 01:28:36,320
Es gibt Hoch- und Tiefpassfilter, Reaktionen auf Streifen und Kanten gibt es dadurch, Reaktionen auf Orientierung.

660
01:28:36,320 --> 01:28:39,320
Das machen einfache Zellen.

661
01:28:39,320 --> 01:28:49,320
Wenn sie auf irgendwelche Muster treffen, werden Nervenimpulse ausgelöst, abhängig davon, was sie da sehen.

662
01:28:49,320 --> 01:28:59,320
Da gibt es also Reaktionen auf horizontale Kanten, auf vertikale Kanten oder auch auf Diagonale.

663
01:28:59,320 --> 01:29:05,320
Es gibt komplexe Zellen, die reagieren auf Streifen und Kanten, die reagieren auf Orientierung,

664
01:29:05,320 --> 01:29:09,320
reagieren auch auf spezielle Bewegungsrichtungen.

665
01:29:09,320 --> 01:29:14,320
Das können sie alles testen, indem sie zum einen gucken, wo gibt es Gehirnaktivität,

666
01:29:14,320 --> 01:29:19,320
und dann zeigen sie eben gewisse spezielle Muster, mit denen sie das frei herauskommen, den Probanden.

667
01:29:24,320 --> 01:29:33,320
Das hier ist etwas, was man auch sehen kann, wenn sie neuronale Netze trainieren, um irgendwelche Bilderkennungssachen zu machen.

668
01:29:34,320 --> 01:29:40,320
Um zu detektieren, ob wir Hunde und Katzen im Bild haben oder ob ein Pferd, ein Auto, ein Mensch oder was auch immer.

669
01:29:40,320 --> 01:29:45,320
Dann kann man auf verschiedenen Stufen neuronaler Netze gucken, was kommen denn da für Ergebnisse raus.

670
01:29:45,320 --> 01:29:56,320
Da gibt es dann auch diese letztendlich primitive, dass es da irgendwelche Merkmale gibt oder Schichten in den Netzwerken,

671
01:29:56,320 --> 01:30:02,320
wo man sehen kann, da werden Orientierungen detektiert, da werden Bewegungsrichtungen orientiert.

672
01:30:02,320 --> 01:30:05,320
Da haben wir eine Erregung, wenn wir Streifen oder Kanten im Bild haben.

673
01:30:07,320 --> 01:30:16,320
Und wenn man jetzt Streifen, Kanten und Orientierungen hat, dann ist der nächste Schritt, dass sie Ecken erkennen oder spezielle Bewegungsrichtungen.

674
01:30:21,320 --> 01:30:30,320
Und ohne dass man das erzwungen hat, hat man letztendlich bei neuronalen Netzen festgestellt,

675
01:30:30,320 --> 01:30:34,320
dass es da nicht nur diese primitive gibt, sondern auch diese, die sich da automatisch einstellen.

676
01:30:34,320 --> 01:30:41,320
Das ist also irgendwo etwas Universelles. Etwas, was hilft, um Bilder zu verstehen.

677
01:30:49,320 --> 01:30:52,320
Wir nehmen Strukturen wahr.

678
01:30:52,320 --> 01:31:01,320
Wir erkennen problemlos, dass die Muster hier alle ähnlich sind.

679
01:31:01,320 --> 01:31:08,320
Wir erkennen auch, dass wir die gleichen Muster haben, nur die Anordnung scheint anders zu sein, die Orientierung ist begrenzt.

680
01:31:09,320 --> 01:31:23,320
Wenn wir uns das hier anschauen, dann sehen wir typischerweise vier Linien.

681
01:31:23,320 --> 01:31:34,320
Wir fassen geometrische Primitive, die nah beieinander sind, zusammen und trennen sie von anderen.

682
01:31:38,320 --> 01:31:46,320
Wir erkennen ganz schnell, was eine geschlossene Linie ist.

683
01:31:46,320 --> 01:31:49,320
Das ist auch etwas, worauf wir reagieren.

684
01:31:49,320 --> 01:31:56,320
Und wir sind in der Lage, Linien fortzusetzen.

685
01:31:56,320 --> 01:32:07,320
Wir erkennen, dass es hier einmal diese Treppenfunktionen gibt.

686
01:32:07,320 --> 01:32:16,320
Wir erkennen auch, dass wir hier noch diesen Kreis haben.

687
01:32:16,320 --> 01:32:19,320
Das sehen Sie.

688
01:32:20,320 --> 01:32:24,320
Wenn Sie etwas anderes gesehen haben,

689
01:32:24,320 --> 01:32:27,320
wenn Sie das hier gesehen haben,

690
01:32:27,320 --> 01:32:30,320
und das hier,

691
01:32:30,320 --> 01:32:38,320
dann sehen Sie nicht normal, um es mal vorsichtig auszudrücken.

692
01:32:38,320 --> 01:32:42,320
Wir sind also darauf trainiert, Linien fortzusetzen.

693
01:32:42,320 --> 01:32:46,320
Und sei es dadurch, dass wir im realen Leben letztendlich das Konzept der Verdeckung kennen.

694
01:32:46,320 --> 01:32:49,320
Sie wollen irgendetwas erkennen und da liegt ein Blatt Papier drüber,

695
01:32:49,320 --> 01:32:52,320
dann erkennen Sie trotzdem, wenn Sie genug von dem darunterliegenden erkennen,

696
01:32:52,320 --> 01:32:57,320
das ist doch die Uhr, die ich da suche, oder das ist die Form meines Handys oder des Hammers,

697
01:32:57,320 --> 01:33:01,320
oder was auch immer Sie da suchen.

698
01:33:01,320 --> 01:33:12,320
Das hier sind dann letztendlich auch Konzepte, die man in der Bildbearbeitung umsetzen will, realisieren will.

699
01:33:13,320 --> 01:33:21,320
Wir nehmen Strukturen wahr, indem wir den Informationsgehalt versuchen zu minimieren,

700
01:33:21,320 --> 01:33:25,320
indem wir Linien uns dazudenken.

701
01:33:32,320 --> 01:33:35,320
Wir sehen hier zum Beispiel,

702
01:33:35,320 --> 01:33:40,320
Dreikreise und darauf liegt ein Dreieck.

703
01:33:43,320 --> 01:33:48,320
Hier sehen wir drei Quadrate,

704
01:33:48,320 --> 01:33:56,320
dazwischen liegt ein Dreieck und ganz oben drauf liegt noch ein Dreieck.

705
01:33:57,320 --> 01:34:07,320
Und auch die meisten von uns werden hier einen Würfel erkennen.

706
01:34:07,320 --> 01:34:14,320
Wir versuchen das, was wir an Linien sehen, räumlich zu interpretieren.

707
01:34:14,320 --> 01:34:17,320
Warum machen wir das? Naja, weil wir es so gelernt haben.

708
01:34:17,320 --> 01:34:22,320
Das Foto ist nicht etwas, was uns Natur gegeben ist, das ist irgendwo eine Erfindung der Neuzeit.

709
01:34:22,320 --> 01:34:29,320
Auch ein Gemälde ist etwas, das der Menschheit nicht in die Wiege gelegt wurde,

710
01:34:29,320 --> 01:34:32,320
sondern 3D-Körper.

711
01:34:32,320 --> 01:34:37,320
Und die 3D-Körper werden natürlich im Auge ein zweidimensionales Bild.

712
01:34:37,320 --> 01:34:42,320
Aber wir wissen dann aus der Erfahrung, das ist ein 3D-Körper und mithilfe dieser Erfahrung sind wir dann auch in der Lage zu sagen,

713
01:34:42,320 --> 01:34:47,320
aha, hier haben wir die Vorderseite des Würfels und hier hinten ist die Rückseite

714
01:34:47,320 --> 01:34:52,320
und offensichtlich guckt man dann irgendwie aus dieser Richtung auf den Würfel drauf.

715
01:34:59,320 --> 01:35:07,320
Jetzt haben wir hier noch ein interessantes Bild, was die Rechenleistung angeht.

716
01:35:07,320 --> 01:35:15,320
Wir wollen ja letztendlich versuchen, Bilder zu interpretieren mithilfe von Computern

717
01:35:15,320 --> 01:35:19,320
und die Referenz ist sicherlich der Mensch.

718
01:35:19,320 --> 01:35:27,320
In Spezialanwendungen ist der Computer heute besser, Bilder zu analysieren, als es der Mensch ist.

719
01:35:27,320 --> 01:35:32,320
Aber die Universalität, die wir als Mensch bei der Interpretation von Bildern haben,

720
01:35:32,320 --> 01:35:40,320
die ist natürlich viel besser als das, was der Computer heute kann.

721
01:35:40,320 --> 01:35:45,320
Jetzt haben wir hier mal aufgetragen die Zeitachse.

722
01:35:45,320 --> 01:35:55,320
Nach oben Rechenleistung, und zwar Rechenleistung logarithmisch.

723
01:35:55,320 --> 01:36:01,320
Und Sie wissen, wenn wir Zeit linear haben, Rechenleistung logarithmisch,

724
01:36:01,320 --> 01:36:05,320
und wir zeichnen da eine Gerade rein, dann haben wir Moore's Law.

725
01:36:05,320 --> 01:36:10,320
Das ist natürlich kein Gesetz, kein Naturgesetz, sondern das ist eine Beobachtung,

726
01:36:10,320 --> 01:36:15,320
wie hat sich die Technik in den letzten Jahren entwickelt.

727
01:36:15,320 --> 01:36:20,320
Da kann man jetzt alle möglichen Prozessoren einreichen.

728
01:36:20,320 --> 01:36:30,320
Man kann auch mal gucken, welche Rechenleistung gibt es denn so in der Natur.

729
01:36:30,320 --> 01:36:43,320
Dann haben wir hier die Rechenleistung von einem Wurm, einer Echse, einem Affen und einem Mensch.

730
01:36:43,320 --> 01:36:48,320
2020 sind wir jetzt vielleicht ungefähr hier.

731
01:36:48,320 --> 01:36:53,320
Es dauert nicht mehr lange, dann werden wir auch so viel Rechenleistung haben in den Computern,

732
01:36:53,320 --> 01:36:57,320
wie wir das als Mensch haben.

733
01:36:57,320 --> 01:37:00,320
Es fehlt aber noch an der Intelligenz in der Software.

734
01:37:00,320 --> 01:37:07,320
Von daher müssen Sie sich wohl noch keine Gedanken machen, dass Sie vom Computer dominiert werden.

735
01:37:07,320 --> 01:37:12,320
Man kann untersuchen, wie der Mensch sieht.

736
01:37:12,320 --> 01:37:17,320
Wir hatten gesehen, es gab da Nervenzellen, die haben auf ein gewisses Muster reagiert.

737
01:37:17,320 --> 01:37:21,320
Damit hat man also ein Beispiel, wie man das machen kann.

738
01:37:21,320 --> 01:37:27,320
Man kann sich jetzt überlegen, wie man den Menschen nachbilden kann.

739
01:37:27,320 --> 01:37:35,320
Zurzeit macht man das gerne mit Convolutional Neural Networks.

740
01:37:35,320 --> 01:37:49,320
Mein früherer Kollege Jan Lacan hat da die neuronalen Netze damals für Schriftzeichenerkennung für die amerikanische Post entwickelt.

741
01:37:50,320 --> 01:37:59,320
Er hat sich da letztendlich ein bisschen an dem orientiert, was man von menschlichen visuellen Sehen weiß.

742
01:37:59,320 --> 01:38:06,320
Man weiß, die Zellen sind miteinander verschaltet in einer lokalen Nachbarschaft.

743
01:38:06,320 --> 01:38:15,320
Dann gibt es letztendlich eine Zellebene nach der anderen, eine hierarchische Struktur, bis man dann irgendwann zu der Erkenntnis kommt.

744
01:38:15,320 --> 01:38:25,320
Das wurde dann umgesetzt in neuronale Netze, wo wir von einem Eingangsbild dann lokal irgendwelche Filteroperationen durchführen.

745
01:38:25,320 --> 01:38:31,320
Ein Teil der Nerven nimmt dann von einer Ebene zumindest ab.

746
01:38:31,320 --> 01:38:36,320
Das heißt, wir haben eine Unterabtastung, wir haben dann mehrere parallele Verarbeitungen

747
01:38:36,320 --> 01:38:46,320
und kriegen dann zum Schluss ein Muster, aus dem wir dann aufgrund der Reaktion, die man dann kriegt, ableiten können, was wir sehen.

748
01:38:46,320 --> 01:39:03,320
Das war damals ein relativ einfaches Netz, was man mit 10 auf 7 Bildpunkten trainieren konnte.

749
01:39:04,320 --> 01:39:15,320
Heute haben sie Netze, da brauchen sie Unmengen von Daten, um sie zu trainieren, weil sie einfach auch unfassbar viel größer sind als das, was man heute kann.

750
01:39:15,320 --> 01:39:22,320
Was man braucht, gerechnet wird das heute nicht mehr auf CPUs, sondern auf diese GPUs.

751
01:39:22,320 --> 01:39:30,320
Wenn Sie am Mining interessiert sind, dann stellen Sie fest, die GPUs werden immer teurer

752
01:39:30,320 --> 01:39:36,320
und wenn Sie nur spielen wollen, dann ärgern Sie sich über die, die Mining machen, weil die GPUs teurer werden.

753
01:39:36,320 --> 01:39:42,320
Denn die GPUs werden heute gebraucht, nicht nur für Spiele, sondern letztendlich in kommerziellen Anwendungen,

754
01:39:42,320 --> 01:39:53,320
im großen Teil für das Trainieren von neuronalen Netzen und dann natürlich auch noch die, die an Bitcoin und Ähnliches glauben.

755
01:39:53,320 --> 01:40:01,320
So ein neuronales Netz ist eine Emulation dessen, was das menschliche visuelle System macht.

756
01:40:01,320 --> 01:40:13,320
Ausgehend von einem Bild haben wir dann einfach eine ganz klassische Faltungsoperation.

757
01:40:14,320 --> 01:40:21,320
Ja, Sie können sich überlegen, ist das der Filter, der da angewendet wird? Hat die Länge 3, 5, 7?

758
01:40:21,320 --> 01:40:28,320
Haben Sie irgendwelche Tricks und machen da einen Filter der Länge 20 draus? Aber es ist eine lineare Filteroperation.

759
01:40:28,320 --> 01:40:36,320
Das Ergebnis der Filterung wird durch eine Nicht-Linearität geschickt.

760
01:40:37,320 --> 01:40:43,320
Das könnte so eine Funktion sein. Hier Eingang, hier Ausgang.

761
01:40:43,320 --> 01:40:52,320
Und eine ganz beliebte Nicht-Linear-Funktion, die da implementiert wird, ist für negative Eingangswerte 0 und dann geht es linear hoch.

762
01:40:52,320 --> 01:41:01,320
Letztendlich eine triviale Nicht-Linearität. Reicht aber, um das menschliche Sehen nachzubilden.

763
01:41:01,320 --> 01:41:06,320
Nach dieser Nicht-Linearität falten Sie wieder und wieder die Nicht-Linearität.

764
01:41:06,320 --> 01:41:13,320
Dann fassen Sie irgendwelche Ergebnisse zusammen von benachbarten Nervenzellen.

765
01:41:13,320 --> 01:41:21,320
Wenn Sie so wollen, wird nur das Maximum weitergeleitet. Sie falten wieder, Nicht-Linearität, Maximumsuche, falten und so weiter.

766
01:41:22,320 --> 01:41:31,320
Zum Schluss kommen Sie dann hier irgendwo an ein Endergebnis, wo Sie dann, wenn Sie, was weiß ich, sich für Hunde, Katzen, Pferde, Flugzeuge interessieren,

767
01:41:31,320 --> 01:41:36,320
zehn Klassen haben oder auch tausend Klassen. Solche Netzwerke gibt es auch.

768
01:41:36,320 --> 01:41:46,320
Und jede dieser Nervenzellen sagt Ihnen, wie wahrscheinlich ist es, dass es sich um Hund, Katze, Pferd handelt.

769
01:41:46,320 --> 01:41:56,320
Und von diesen tausend Klassen, die Sie dann hier womöglich haben, sagen Sie, ich sehe das, was der Klasse entspricht, die da den größten Ausschlag hat.

770
01:41:56,320 --> 01:41:58,320
Und dann ist es vielleicht der LK.

771
01:41:58,320 --> 01:42:12,320
So, was sollten Sie mitnehmen?

772
01:42:12,320 --> 01:42:23,320
Die technischen Daten unseres Auges. Also die örtliche Auflösung, die ist irgendwo zwischen 0,5 und 2 Winkelminuten.

773
01:42:24,320 --> 01:42:38,320
Es gibt das weberische oder weber-technische Gesetz, was sagt, damit ich eine Helligkeitsänderung,

774
01:42:38,320 --> 01:42:43,320
Entschuldigung, eine Intensitätsänderung wahrnehmen kann.

775
01:42:43,320 --> 01:42:49,320
Die Intensität war das physikalische Maß, Helligkeit das, was ich als Mensch sehe.

776
01:42:49,320 --> 01:42:59,320
Eine Veränderung in der Physik kann ich wahrnehmen, abhängig von dem I.

777
01:42:59,320 --> 01:43:05,320
Das Delta-I über I muss für viele Fälle größer als 0,1 sein, damit Sie es sehen können.

778
01:43:05,320 --> 01:43:17,320
Das weberische Gesetz. Das marschische Gesetz sagt letztendlich, an Kanten, an Sprüngen erfolgt eine Hochpass-Filterung.

779
01:43:17,320 --> 01:43:39,320
Das heißt, wenn wir hier die Ortskoordinate haben, x, und nach hier oben die Intensität.

780
01:43:39,320 --> 01:43:58,320
Wenn wir so einen Sprung haben, links dunkel, rechts hoch. Das, was wir sehen, ist so etwas.

781
01:43:58,320 --> 01:44:03,320
Auf der dunklen Seite der Kante, direkt an der Kante, ist das Signal besonders dunkel.

782
01:44:03,320 --> 01:44:15,320
Auf der hellen Seite der Kante, dicht an der Kante, nehmen wir das Signal als besonders hell wahr.

783
01:44:15,320 --> 01:44:21,320
Durch die Analyse des menschlichen visuellen Systems kommt man zu dem Schluss,

784
01:44:21,320 --> 01:44:29,320
dass für die Interpretation von Bildern, für die Wahrnehmung, Helligkeitsübergänge, Kanten und Ecken von Bedeutung sind.

785
01:44:29,320 --> 01:44:43,320
Die Erfassung von lokalen Bewegungen ist wichtig und die Helligkeit, die Intensität, das Schwarz-Weiß-Signal ist wichtiger als die Farbe.

786
01:44:43,320 --> 01:44:56,320
Wenn man das so macht, dann geht man davon aus, dass man mit dem Bildverarbeitungssystem letztendlich das menschliche Herangehen an die Bildanalyse nachbauen will.

787
01:44:56,320 --> 01:45:04,320
Das muss nicht der optimale Ansatz sein, aber das ist das, wie man es heute erstmal macht.

788
01:45:05,320 --> 01:45:12,320
Es hätte auch sein können, dass die Evolution an irgendeiner Stelle einen anderen Weg einschlägt und wir dann anders die Bilder interpretieren.

789
01:45:12,320 --> 01:45:21,320
Aber so machen wir es und zurzeit ist das letztendlich auch das Vorgehen, wie wir das in realen Systemen umsetzen.

790
01:45:21,320 --> 01:45:29,320
Was die Rechenleistung angeht, hier steht jetzt die Rechenleistung gegenüber dem menschlichen visuellen System begrenzt.

791
01:45:30,320 --> 01:45:38,320
Was aber ein Trugschluss wäre, wir können heute einen Superrechner bauen und die gibt es auch schon, die können mehr rechnen als ein menschliches Gehirn.

792
01:45:38,320 --> 01:45:40,320
Das bedeutet aber nicht, dass sie schlauer sind.

793
01:45:40,320 --> 01:45:46,320
Die Intelligenz der Software ist ein weiteres Problem, was noch nicht gelöst ist.

794
01:45:46,320 --> 01:45:57,320
Die Intelligenz der Softwarelösung, die wir heute haben, ist gegenüber dem menschlichen System derzeit noch sehr begrenzt und das ist etwas, was wir nicht durch schnellere Rechner lösen können.

795
01:46:00,320 --> 01:46:07,320
So, das war der Mensch. Kommen wir jetzt zu dem, was der Mensch baut, Kameras, Sensoren.

796
01:46:07,320 --> 01:46:14,320
Wie können wir digitale Bilder erfassen und welche Größen können wir in diesen Bildern aufnehmen?

797
01:46:14,320 --> 01:46:32,320
Wenn wir ein digitales Bild erzeugen, dann muss es erstmal etwas geben, was dieses Bild aufnehmen oder darstellen soll. Das ist die reale Welt.

798
01:46:32,320 --> 01:46:42,320
In der realen Welt haben wir Objekte oder Szenenelemente.

799
01:46:42,320 --> 01:46:58,320
Wir haben die Szenenbeleuchtung und die Energie, die diese Beleuchtungsquelle abstrahlt, wird von dem Objekt reflektiert in alle möglichen Richtungen, unter anderem auch in die Richtung unseres Sensors.

800
01:46:59,320 --> 01:47:16,320
Der Sensor sammelt das Licht auf, innen drin eine gerasterte Bildebene und der Sensor für jeden Bildpunkt merkt er sich, wie viel Energie ist da gekommen und das ist dann unser Bild.

801
01:47:16,320 --> 01:47:38,320
In einer idealen Welt ist unser Sensor als Lochkamera repräsentiert. Das kennen Sie aus dem Physikunterricht und der Strahlensatz gilt. Den kennen Sie auch aus der Schule.

802
01:47:38,320 --> 01:47:58,320
Wir haben hier das Bild und hier das Objekt. Alle Strahlen, Lichtstrahlen, die auf dem Bild landen, müssen durch die Lochblende durch.

803
01:47:58,320 --> 01:48:18,320
Die Lochblende hier ist eine Blende, die ist infinitesimal klein. Ein mathematischer Punkt.

804
01:48:18,320 --> 01:48:38,320
Der Sensor ist mit den Koordinaten x1, x2 und x3 als Abstand der Objektebene von der Blende.

805
01:48:38,320 --> 01:49:00,320
Der Sensor ist mit den Koordinaten x1, x2 und x3 als Abstand der Objektebene von der Blende.

806
01:49:00,320 --> 01:49:16,320
Es gibt verschiedene Realisierungen eines solchen Sensors. CMOS-Sensoren, LCD-Sensoren. Die CMOS-Sensoren sind die billigeren, weil Sie sie genauso herstellen können wie Integrierte Schaltungen.

807
01:49:16,320 --> 01:49:31,320
Hier sehen Sie eine Kamera. Das hier sind vielleicht 5 cm. Der Sensor selbst ist vielleicht so groß wie ein Zentstück.

808
01:49:31,320 --> 01:49:51,320
Die gibt es in unterschiedlichen Größen. Wenn Sie eine klassische Kamera haben, die so ein halbes Kilo wiegt, dann haben Sie einen Vollformat-Sensor. Der wäre dann die Ausrichtung hier. Das wären 36 mm, das wären 24 mm.

809
01:49:51,320 --> 01:50:14,320
Aber es gibt auch Sensoren, die sind nur ein Bruchteil davon ein Zehntel so groß. Die Größe des Sensors entscheidet über die Anzahl der Bildpunkte, die da sind und natürlich auch über die Energiemenge, die aufgenommen werden kann.

810
01:50:14,320 --> 01:50:34,320
Je größer der Sensor ist, desto mehr Energie kann er aufnehmen. Ein größerer Sensor bedeutet auch, Sie brauchen eine größere Linse davor. Das Ganze wird also schwerer. Nur weil Ihr Sensor größer wird, muss er nicht mehr Bildpunkte haben.

811
01:50:34,320 --> 01:50:54,320
Wenn Sie dann noch einen großen Sensor nehmen mit vielleicht nur 10 Megapixeln und manchmal haben Sie einen kleinen Sensor, wie am Handy, der hat 20 Megapixel. Wenn Sie einen großen Bildpunkt haben, können Sie sich vorstellen, dann sammelt er viel Energie auf, der misst also zuverlässig.

812
01:50:54,320 --> 01:51:06,320
Wenn Sie einen kleinen Bildpunkt haben, von der Größe her, dann kann er nicht so viel Energie aufsammeln, der misst nicht so zuverlässig. Oder auch anders gesprochen, der kleine Sensor wird mehr rauschen als der große.

813
01:51:06,320 --> 01:51:24,320
Die Halbleiterbildsensoren haben im Vergleich zu der Filmkamera mit dem physikalischen Film, den man früher so hatte, eine ganz präzise und stabile Geometrie. Das sind Präzisionsgeräte.

814
01:51:24,320 --> 01:51:42,320
So ein Sensor ist klein, er ist robust, er hat auch eine hohe Sensitivität, er reagiert schon auf wenig Licht im Vergleich zum klassischen chemischen Film. Da braucht es viel mehr Licht, um vernünftige Bilder zu erzeugen. Das ist mit diesen CMOS-Sensoren viel einfacher.

815
01:51:42,320 --> 01:52:00,320
Die CMOS-Sensoren können Sie natürlich in allen möglichen Konfigurationen herstellen. Sie können die Anzahl der Bildpunkte variieren, Sie können die Größe der Bildpunkte variieren, Sie können die Geschwindigkeit des Sensors variieren.

816
01:52:00,320 --> 01:52:24,320
Wie lange braucht der Sensor, um die ganzen Informationen aus den Bildpunkten rauszulesen und auf einen Bus zu schreiben? Das wäre dann, was sich hier unter Bildrate verbirgt. Und Auflösung des Sensors ist auch etwas, was nicht nur räumlich angeht. Das ist der 20 Megapixel-Sensor.

817
01:52:24,320 --> 01:52:48,320
Das kann auch die Amplitudenauflösung sein. Liefert der Sensor pro Bildpunkt 8 Bit, was Ihr Handy macht? Oder 10 Bit? Das ist das, was Ihr HD- oder UHD-Fernseher, den Sie zu Hause haben, darstellt.

818
01:52:48,320 --> 01:53:11,320
Oder ist das eine Kamera, die im Studio eingesetzt wird, die typischerweise mit 12 Bit Amplitudenauflösung betrieben wird, heute in den modernen Studios? Also Auflösung gibt es drei Größen. Das ist die Größe des Sensors, die Größe der Bildpunkte und dann auch noch die Amplitudenauflösung.

819
01:53:12,320 --> 01:53:26,320
Sie können auch mit diesen Sensoren Dinge sichtbar machen, die wir als Menschen sehen können. Sie wissen, es gibt Insekten, die sehen andere Frequenzbereiche als wir. Das können Sie mit so einem CMOS-Sensor auch machen.

820
01:53:26,320 --> 01:53:46,320
Wir haben in diesem Bild einmal aufgetragen, hier Wellenlänge des Lichtes. Sollte man sich vielleicht merken, UV-Licht, ultraviolettes Licht hat eine kurze Wellenlänge, eine hohe Frequenz. Das rote Licht und dann gibt es den Infrarotbereich, das ist längerwelliges Licht.

821
01:53:47,320 --> 01:53:56,320
Wir können sehen, von blau bis rot, ultraviolettes Licht sehen wir nicht und Infrarotlicht sehen wir auch nicht.

822
01:53:57,320 --> 01:54:16,320
Wir sehen hier gepunktet die Empfindlichkeit des menschlichen Auges, die ist hier nach oben aufgetragen. Es gibt also einen Frequenzbereich, wir haben so einen Bereich Grün-Gelb, da sind wir besonders empfindlich. Im Bereich Rot sind wir nicht so empfindlich.

823
01:54:16,320 --> 01:54:31,320
Heißt, da muss viel rotes Licht kommen, damit wir es sehen. Bei grünem Licht brauchen wir nicht so viel Intensität, um es wahrnehmen zu können.

824
01:54:31,320 --> 01:54:44,320
Dann gibt es die technischen Sensoren, CMOS oder CCD. Da sehen Sie, die haben beide einen wesentlich größeren Frequenzbereich, den sie abdecken.

825
01:54:44,320 --> 01:55:12,320
Das heißt, wir können damit auch Bilder im ultravioletten Bereich sehen oder auch im Infrarotbereich. Im Infrarotbereich ist dann auch Wärme, also Wärmebildkameras, die haben letztendlich Filter, die dafür sorgen, dass nur dieser Wellenlängenbereich vom Sensor erfasst wird und dann können sie gucken, ob ihr Haus ordentlich isoliert ist oder können das dann auch nutzen, um die Temperatur zu messen.

826
01:55:14,320 --> 01:55:34,320
Wenn sie jetzt Farbe wahrnehmen wollen mit einem technischen Gerät, dann brauchen sie Filter. Also ein CMOS-Sensor hat eine gewisse Empfindlichkeit.

827
01:55:34,320 --> 01:55:54,320
Wenn sie hier im Infrarotbereich eine gewisse Intensität erzeugen, dann schlägt der Sensor voll auf. Wenn sie die gleiche Intensität im UV-Bereich nehmen, dann wird der Sensor nicht so stark ausschlagen. Das heißt ja diese Kurve.

828
01:55:54,320 --> 01:56:09,320
Wenn sie sich jetzt aber dafür interessieren, wenn sie sich für die Wellenlänge des Lichtes interessieren, hilft dem Sensor erstmal gar nichts. Der reagiert letztendlich auf jegliche Energie in diesem Spektralbereich.

829
01:56:09,320 --> 01:56:24,320
Wenn sie sich jetzt für rotes Licht interessieren, dann müssen sie vor die Kamera oder vor den Bildpunkt einen Filter setzen, der nur eine gewisse Bandbreite an Licht durchlässt.

830
01:56:24,320 --> 01:56:46,320
Wenn sie jetzt eine Farbkamera haben, dann gibt es da RGB, Rot-Grün-Blau-Sensoren. Das bedeutet, dass vor die lichtempfindlichen Elemente, CMOS oder DCD, Filter gesetzt werden.

831
01:56:46,320 --> 01:56:59,320
So dass durch den einen Filter nur die blaue Lichtenergie durchkommt, durch den anderen nur die grüne und durch den anderen nur die rote.

832
01:57:00,320 --> 01:57:18,320
Damit sind wir dann bei der Videofarbkamera. Da gibt es zwei Varianten. Da gibt es die Variante, die wir alle in unserem Handy haben und dann gibt es die Variante, die man vielleicht in dem einen oder anderen Videokamera hat.

833
01:57:18,320 --> 01:57:34,320
Die Handys, das kann eine Bildkamera sein oder eine Videokamera, das ist egal, die haben vor den einzelnen Bildpunkten des Sensors einen Farbfilter.

834
01:57:35,320 --> 01:57:46,320
Die typische Anordnung ist so, sie haben einen Block von vier Bildpunkten auf ihrem Chip.

835
01:57:47,320 --> 01:57:54,320
Für einen Bildpunkt ist ein Rotfilter, da kommt nur das rote Licht durch.

836
01:57:55,320 --> 01:57:59,320
Wegen ein Grünfilter, da kommt nur das grüne Licht durch.

837
01:58:01,320 --> 01:58:06,320
Und einen Bildpunkt Richtung Blaufilter, da geht nur das blaue Licht durch.

838
01:58:06,320 --> 01:58:31,320
Wenn man jetzt mal die Bildpunkte zählen würde, dann stellt man also fest, der Sensor hat zum Beispiel 20 Millionen Bildpunkte, dann werden 10 Millionen Bildpunkte, also die Hälfte, werden grünes Licht aufsammeln und rotes und blaues Licht werden von jemals 5 Millionen Bildpunkten aufgesammelt.

839
01:58:37,320 --> 01:59:01,320
Aus diesen vier örtlich benachbarten Bildpunkten werden dann, je nach System, meistens vier Bildpunkte berechnet, die die Komponenten Rot, Grün und Blau haben.

840
01:59:02,320 --> 01:59:17,320
Das heißt, wir nehmen vier Zahlen auf dem Sensor, dann gibt es eine Berechnung und dann kommen zwölf Zahlen raus, vier Bildpunkte jeweils mit RGB.

841
01:59:17,320 --> 01:59:32,320
Das funktioniert natürlich irgendwo gut, aber wenn Sie ganz, ganz genau hingucken, dann wird das nicht so gut funktionieren, denn das, was der blaue oder der rote Sensor aufnimmt, ist gegeneinander örtlich verschoben.

842
01:59:33,320 --> 01:59:41,320
Wenn Sie das jetzt umrechnen in RGB für diesen Bildpunkt, dann müssen Sie da Filteroperationen vornehmen, die irgendwo eine Unschärfe erzeugen.

843
01:59:41,320 --> 02:00:00,320
Wenn Sie also besonders gute Bildqualität haben wollen, dann nehmen Sie eine 3-Chip-Kamera. Das Licht läuft auf ein Prisma. Das Prisma teilt das Licht auf in drei Lichtstrahlen.

844
02:00:00,320 --> 02:00:15,320
Das Licht kommt hier rein, kommt aus dem Prisma hier, hier und hier raus. Dann setzen Sie da Farbfilter vor. Dann haben Sie drei Sensoren.

845
02:00:15,320 --> 02:00:32,320
Wenn Sie jetzt hier drei 20-Megapixel-Sensoren haben, können Sie hinterher 20 Millionen Bildpunkte erzeugen, für die Sie einen Grünwert, einen Rotwert und einen Blauwert haben.

846
02:00:32,320 --> 02:00:45,320
Und natürlich müssen Sie bei der Produktion darauf achten, dass Ihre Chips so angeordnet sind, dass dieser Bildpunkt genau das gleiche Licht abkriegt wie dieser Bildpunkt, genau das gleiche Licht wie dieser Bildpunkt.

847
02:00:46,320 --> 02:00:56,320
Diese 3-Chip-Kameras gibt es viele, sind halt ein bisschen teurer, weil natürlich aufwendiger und Sie können sie auch nicht ins Handy setzen, weil Sie ja irgendwie mehr Platz brauchen.

848
02:01:02,320 --> 02:01:10,320
Ich habe hier gesagt, da werden Filter vor die Bildpunkte gesetzt. Was für Möglichkeiten gibt es denn da?

849
02:01:11,320 --> 02:01:19,320
Also eine Möglichkeit wäre, Sie setzen gar keine Filter davor. Das heißt, Sie hätten dann einen Monochrom-Sensor, einen Schwarz-Weiß-Sensor.

850
02:01:20,320 --> 02:01:30,320
Ganz verbreitet ist das sogenannte Bayer-Pattern. Zweimal Grün, einmal Rot, einmal Blau in der Anordnung.

851
02:01:30,320 --> 02:01:57,320
Sony hat sich da was anderes überlegt. Sie benutzen das RGBI-Pattern. Es gibt Sensoren, wo Sie ganze Spalten haben, die nur grünes Licht auffangen und hier Rot-Blau haben.

852
02:01:58,320 --> 02:02:08,320
Es gibt Sensoren, da haben Sie Rot-Grün-Blau und einen Bildpunkt ohne Filter, einen Weiß-Filter.

853
02:02:09,320 --> 02:02:18,320
Es gibt auch ganz andere Farbdarstellungen. Das hier ist ja alles noch irgendwo RGB getrieben. Hier haben wir einen anderen Farbraum.

854
02:02:19,320 --> 02:02:25,320
Das Wichtigste im Sinne von am weitesten verbreitet ist das Bayer-Pattern.

855
02:02:25,320 --> 02:02:40,320
Jetzt haben wir vielleicht verstanden, wie das Licht auf den Sensor kommt.

856
02:02:41,320 --> 02:02:50,320
Jetzt müssen die Daten aus dem Sensor herausgelesen werden und die Frage ist, wann sammeln Sie das Licht ein?

857
02:02:50,320 --> 02:03:00,320
Bei der mechanischen Kamera läuft ein Verschluss vorweg vor dem Sensor.

858
02:03:01,320 --> 02:03:11,320
Idealerweise ist das so, dass der alle Bildpunkte gleichzeitig belichtet und dann für alle Bildpunkte gleichzeitig das Licht ausschaltet.

859
02:03:11,320 --> 02:03:17,320
Es gibt solche Kameras, die nennen sich Global Shutter.

860
02:03:18,320 --> 02:03:24,320
Da werden alle Bildpunkte gleichzeitig belichtet und dann wird das Licht mechanisch ausgeschaltet.

861
02:03:25,320 --> 02:03:31,320
Dann hat man Zeit, um die Werte auszulesen.

862
02:03:32,320 --> 02:03:37,320
Es gibt auch das Konzept des Rolling Shutter.

863
02:03:38,320 --> 02:03:43,320
Da belichten Sie Ihren Sensor zeilenweise.

864
02:03:44,320 --> 02:04:04,320
Wenn Sie jetzt 50 Bilder pro Sekunde aufnehmen, dann wird die 50. Sekunde, die Sie haben, die ganze Zeit über etwas ausgelesen.

865
02:04:05,320 --> 02:04:10,320
Zu Beginn der 50. Sekunde wird die erste Zeile ausgelesen, zum Ende der 50. Sekunde die letzte Zeile und dann geht es wieder um.

866
02:04:10,320 --> 02:04:17,320
Das bedeutet, ein Bild wird über einen Zeitraum aufgenommen, nicht zu einem Zeitpunkt.

867
02:04:18,320 --> 02:04:30,320
Wenn sich jetzt in diesem Bild etwas schnell bewegt, dann sehen Sie das in dem Bild auch, weil etwas, was eine senkrechte Linie ist, dann so weit versetzt gekommen ist.

868
02:04:30,320 --> 02:04:41,320
Als die oberste Zeile hier aufgenommen wurde, stand das Gebäude da und das stand immer noch an der gleichen Stelle, als diese Zeile aufgenommen wurde.

869
02:04:42,320 --> 02:04:45,320
Das Gebäude hat sich nicht bewegt und in diesem Fall hat sich wohl auch die Kamera nicht bewegt.

870
02:04:46,320 --> 02:04:56,320
Das Auto wiederum war zu Anfang hier an dieser Stelle und hat sich weiter bewegt und nach und nach wurden die Bildzeilen aufgenommen.

871
02:04:56,320 --> 02:05:00,320
Als wir an dieser Zeile waren, war das Auto dann eben um diese 30 Zentimeter weiter weg.

872
02:05:01,320 --> 02:05:14,320
Aus diesem Bild, unter der Annahme, dass der Kasten dieses LKWs senkrecht ist, können Sie auch gleich ablesen, wie schnell das Auto gefahren ist, unter der Annahme, dass Sie wissen, wie die Belichtungszeit des Autos war.

873
02:05:15,320 --> 02:05:23,320
Wenn Sie so eine Kamera mit einem Global Shutter haben und Sie sehen, was weiß ich, Rotorblätter von Hubschrauber, dann sehen Sie, dass die Kurven gebogen werden.

874
02:05:24,320 --> 02:05:25,320
Alles, was sich schnell bewegt, wird dann krumm dargestellt.

875
02:05:26,320 --> 02:05:37,320
Das kann man also gleich erkennen, ob etwas mit einer preiswerten Kamera, das wäre der Rolling Shutter, das muss billiger sein als das gleichzeitige Licht, oder ob da etwas mit einem Global Shutter aufgenommen wird.

876
02:05:38,320 --> 02:05:43,320
Je nachdem, was Ihre Anwendung ist, ist das für Sie von Bedeutung.

877
02:05:44,320 --> 02:05:51,320
Für Naturfotografie, Landschaftsaufnahmen ist sicherlich der Rolling Shutter gar kein Problem, oder Architekturaufnahmen.

878
02:05:52,320 --> 02:05:58,320
Wenn Sie aber schnell bewegende Objekte erfassen wollen, dann ist Global Shutter die Methode der Wahl.

879
02:05:59,320 --> 02:06:04,320
Alles, was ich Ihnen eben versucht habe zu erzählen, das sehen Sie auf diesem Bild auch noch.

880
02:06:07,320 --> 02:06:19,320
Sie haben gegebenenfalls bei einem Rolling Shutter auch eine längere Berichtungszeit pro Zeile.

881
02:06:20,320 --> 02:06:29,320
Aber Sie haben eben ein Problem mit der Bewegung.

882
02:06:29,320 --> 02:06:38,320
Wenn wir an eine Kamera denken, denken wir typischerweise an einen zweidimensionalen Sensor.

883
02:06:39,320 --> 02:06:43,320
Es gibt aber viele Kameras, da haben wir nur einen Zeilensensor.

884
02:06:44,320 --> 02:06:58,320
Weil es billiger ist, oder weil so ein Zeilensensor dann vielleicht die 20 Megapixel nebeneinander haben kann, und wir damit eine örtliche Auflösung an dieser einen definierten Stelle.

885
02:06:59,320 --> 02:07:03,320
Da gibt es unterschiedliche Gründe, warum man eine Zeilenkamera haben will.

886
02:07:03,320 --> 02:07:11,320
Also, ein Scanner erreicht eine Zeilenkamera, weil wir ja das Papier über den Scanner bewegen.

887
02:07:12,320 --> 02:07:18,320
Wenn der Scanner ohne Bewegung des Papiers funktionieren soll, dann müssen Sie natürlich einen zweidimensionalen Sensor nehmen.

888
02:07:19,320 --> 02:07:24,320
Da Sie aber das Papier einziehen müssen sowieso, ist das Papier in Bewegung und dann können Sie auch gleich eine Zeilenkamera darunter hängen.

889
02:07:25,320 --> 02:07:32,320
In der industriellen Bildverarbeitung, wir machen zum Beispiel für Schaeffler Identifikation von Metalloberflächen,

890
02:07:33,320 --> 02:07:41,320
da liegen die Teile auf dem Fließband und bewegen sich, da können Sie mit einem Zeilensensor ja prima arbeiten,

891
02:07:42,320 --> 02:07:47,320
weil die zweite Dimension, die Sie noch erfassen müssen, die kriegen Sie ja durch die Bewegung des Objektes.

892
02:07:48,320 --> 02:07:53,320
In der industriellen Bildverarbeitung werden Zeilensensoren gerne eingesetzt.

893
02:07:54,320 --> 02:08:00,320
Ich hatte eben gesagt, Landschaftsaufnahmen, Architekturaufnahmen, da können Sie auch prima einen Rolling Shutter verwenden.

894
02:08:01,320 --> 02:08:08,320
Das heißt, ein Rolling Shutter ist ja letztendlich nichts anderes als, Sie bewegen einen Zeilensensor über die Szene,

895
02:08:09,320 --> 02:08:14,320
wenn Sie also Luftbilder nehmen von der Kamera unter dem Flugzeug oder im Satelliten, mit dem Sie die Erde erfassen wollen.

896
02:08:14,320 --> 02:08:20,320
Das sind typischerweise auch Zeilenkameras, wo die Zweidimensionalität eben durch die Bewegung des Sensors,

897
02:08:21,320 --> 02:08:25,320
sei es durch das Flugzeug oder sei es durch die Bewegung des Satelliten, erfasst wird.

898
02:08:31,320 --> 02:08:37,320
Wenn wir mal schauen, was gibt es denn so für elektromagnetische Strahlung,

899
02:08:38,320 --> 02:08:47,320
wir haben hier unten aufgetragen die Wellenlänge, dann haben wir bei 10 hoch minus 15 Metern kosmische Strahlung,

900
02:08:48,320 --> 02:08:52,320
Jammerstrahlung, Röntgenstrahlung, Röntgenstrahlung sind wir hier vielleicht bei 10 hoch minus 9,

901
02:08:53,320 --> 02:09:01,320
dann haben wir das UV-Licht, Infrarot, Radarsensoren, die sind hier bei einer Wellenlänge von wenigen Zentimetern unterwegs,

902
02:09:02,320 --> 02:09:08,320
Rundfunkwellenlängen sind wir schon bei mehreren Metern bis zu Kilometern, wenn wir auch bei Langwellen denken.

903
02:09:09,320 --> 02:09:19,320
Irgendwo dazwischen, ganz klein, ist das, was wir sehen können, zwischen 400 und 750 Nanometer.

904
02:09:23,320 --> 02:09:30,320
Das ist das, was wir sehen. Die Sensoren können durchaus ganz andere Frequenzbereiche erfassen.

905
02:09:31,320 --> 02:09:42,320
Also Röntgenstrahlung können wir erfassen, entweder schauen wir ins Weltall und gucken mit unseren Sensoren,

906
02:09:43,320 --> 02:09:48,320
gibt es da Röntgenstrahlung, wir können aber genauso gut Röntgenstrahlung selbst erzeugen,

907
02:09:49,320 --> 02:09:58,320
also wir stellen ein Licht an und dann sammeln wir die Energie auf, die bei Röntgenstrahlung typischerweise durch ein Objekt durchscheint.

908
02:10:01,320 --> 02:10:05,320
Auch dieses Licht können wir dann mit technischen Sensoren durchaus wahrnehmen.

909
02:10:06,320 --> 02:10:11,320
Das soll heißen, wenn wir irgendwelche industrielle Anwendungen haben, wenn es also nicht darum geht, ob das Bild schön ist,

910
02:10:12,320 --> 02:10:15,320
oder ob das Bild nicht dafür da ist, dass der Mensch es unbedingt sofort erkennen muss,

911
02:10:16,320 --> 02:10:23,320
dann können wir unsere technischen Probleme vielleicht auch in Frequenzbereichen lösen, die man als Mensch gar nicht wahrnehmen kann.

912
02:10:24,320 --> 02:10:32,320
Das heißt, Bildverarbeitung, Bildsensoren müssen nicht auf diesen ganz kleinen Frequenzbereich beschränkt sein, den wir als Menschen wahrnehmen,

913
02:10:33,320 --> 02:10:39,320
sondern da können wir durchaus Röntgenstrahlung nehmen, Röntgenquellen haben, wir können auch irgendwelche Wärmequellen haben, Infrarotquellen,

914
02:10:40,320 --> 02:10:45,320
oder zu Hause haben wir ja eine Mikrowelle, das ist auch nur ein kleiner Bereich im Infrarotbereich.

915
02:10:46,320 --> 02:10:58,320
Da können wir letztendlich Sensor- und Beleuchtungsquellenkombinationen nehmen, die unser Problem, was wir lösen wollen, lösen,

916
02:10:59,320 --> 02:11:05,320
mit Methoden der Bildverarbeitung, auch wenn die Bilderzeugung nicht in die klassische Bilderzeugung von normalen Kameras

917
02:11:06,320 --> 02:11:09,320
in den Frequenzbereich von 400nm bis vielleicht 780nm fällt.

918
02:11:15,320 --> 02:11:21,320
Hier eine Kamera, die im nahen Infrarot etwas aufnimmt.

919
02:11:24,320 --> 02:11:31,320
Das hier ein Bild, das sollten wir vielleicht mal ignorieren, ein Bild, so wie es der Schwarz-Weiß-Sensor aussieht,

920
02:11:32,320 --> 02:11:37,320
wenn Sie das nahe Infrarot mit dazunehmen in das Bild, dann können Sie da vielleicht erste Dinge erkennen.

921
02:11:37,320 --> 02:11:51,320
Eine Wärmekamera, also hier messen wir im Infrarotbereich, und das sind dann so Anwendungen.

922
02:11:52,320 --> 02:12:00,320
Hier jetzt Thermografie im Bereich, ist mein Haus gut isoliert, und Sie sehen, hier sollte man vielleicht was tun,

923
02:12:00,320 --> 02:12:06,320
das könnte ein Heizkörper sein, der noch so in einer Wand steht, oder in einer Heizkörpernische,

924
02:12:07,320 --> 02:12:12,320
da geht es nicht besonders sinnvoll, hier irgendwelche Wärmebrücken.

925
02:12:15,320 --> 02:12:21,320
Sie können das aber auch machen, das machen wir gerade, wir testen zusammen mit anderen Rotorblättern von Windkraftanlagen

926
02:12:22,320 --> 02:12:27,320
auf Verschleiß, die werden dann in irgendwelchen Anlagen betrieben, werden mechanisch bewegt,

927
02:12:27,320 --> 02:12:30,320
und dann will man wissen, wo geht die Struktur kaputt.

928
02:12:31,320 --> 02:12:36,320
Dann kann man natürlich warten, bis da Risse entstehen, man kann aber auch mit einer Wärmebildkamera rangehen,

929
02:12:37,320 --> 02:12:44,320
oder das Rotorblatt beobachten mit einer Wärmebildkamera, und gucken, wo wird dann die Struktur warm.

930
02:12:45,320 --> 02:12:51,320
Dann weiß man schon, dass es da problematische Stellen gibt, bevor die kaputt gehen.

931
02:12:52,320 --> 02:12:58,320
Ja, am Flughafen gab es ja viel Zirkus über diesen sogenannten Nacktscanner.

932
02:12:59,320 --> 02:13:03,320
Das hier sind Bilder, die aus so einem Scanner herauskommen.

933
02:13:04,320 --> 02:13:10,320
Das, was Sie dann am Flughafen sehen, ist stilisiert, wird irgendwie die Silhouette des Menschen dargestellt,

934
02:13:11,320 --> 02:13:18,320
und dann gibt es ein rotes Kästchen, hier soll dann nochmal von dem Personal,

935
02:13:18,320 --> 02:13:22,320
nachgeguckt werden, was ist denn da.

936
02:13:23,320 --> 02:13:27,320
Aber ich weiß nicht, ob Sie sich noch daran erinnern, so richtig viel kann man hier nicht daran sehen,

937
02:13:28,320 --> 02:13:31,320
also ich würde jetzt nicht unbedingt glauben, dass meine Persönlichkeitsrechte verletzt sind,

938
02:13:32,320 --> 02:13:36,320
wenn Sie so ein Bild von mir sehen würden.

939
02:13:37,320 --> 02:13:43,320
Hier einmal ein Radarbild, das wurde jetzt eingefärbt,

940
02:13:43,320 --> 02:13:49,320
Radarbildern können Sie sehr exakt auch Abstandsmessungen machen,

941
02:13:50,320 --> 02:13:54,320
das ist ja das, was das Radar typischerweise macht,

942
02:13:55,320 --> 02:13:59,320
und hier wurde das jetzt nochmal eingefärbt, um irgendwelche Veränderungen aufzuzeigen.

943
02:14:00,320 --> 02:14:07,320
Aber erstmal im Schwarz-Weiß-Bild wird dann letztendlich codiert, wie weit ist das Objekt vom Radarsensor entfernt.

944
02:14:07,320 --> 02:14:13,320
Und da sind wir dann in Wellenlängenbereichen von 3 bis 4 mm bis 20 m,

945
02:14:14,320 --> 02:14:18,320
die wir mit dem menschlichen Auge auch wieder gar nicht wahrnehmen können.

946
02:14:19,320 --> 02:14:23,320
Genauso beim Röntgenbild sind wir auch in Wellenlängenbereichen,

947
02:14:24,320 --> 02:14:27,320
die wir als Mensch nicht wahrnehmen können.

948
02:14:28,320 --> 02:14:32,320
Bei Röntgenquellen ist es letztendlich so, zumindest im medizinischen Bereich,

949
02:14:32,320 --> 02:14:36,320
da haben wir dann eine Röntgenquelle, und hier haben wir unseren Bildsensor.

950
02:14:37,320 --> 02:14:41,320
Wir nehmen auf, das Licht, was aus der Quelle ankommt,

951
02:14:42,320 --> 02:14:47,320
und was dann auch hier gegebenenfalls durch das Objekt, was wir durchleuchten,

952
02:14:48,320 --> 02:14:52,320
wieder entdeckt wird.

953
02:14:53,320 --> 02:14:57,320
Die Röntgenaufnahme ist also etwas kleiner,

954
02:14:57,320 --> 02:15:01,320
als die typische Fotoaufnahme.

955
02:15:02,320 --> 02:15:06,320
Wir werden bei einer Fotografie nicht auf die Idee kommen,

956
02:15:07,320 --> 02:15:11,320
die Kamera hinter die Linie Beleuchtung-Objekt zu stellen.

957
02:15:12,320 --> 02:15:16,320
Bei einer typischen Fotoaufnahme hätten wir hier die Lichtquelle,

958
02:15:17,320 --> 02:15:21,320
und das Licht wird reflektiert.

959
02:15:22,320 --> 02:15:26,320
Und hier haben wir dann unsere Kamera.

960
02:15:27,320 --> 02:15:31,320
Das Licht geht typischerweise durch, wird gedämpft durch die Objekte,

961
02:15:32,320 --> 02:15:36,320
und dann haben wir entsprechend hinter dem Objekt die Kamera.

962
02:15:37,320 --> 02:15:41,320
Aus der Schwächung des Lichtes

963
02:15:42,320 --> 02:15:46,320
leitet man dann letztendlich ab,

964
02:15:47,320 --> 02:15:51,320
was man da für Materialien hat,

965
02:15:52,320 --> 02:15:56,320
oder Gewebe und Ähnliches.

966
02:15:57,320 --> 02:16:01,320
Wenn Sie eine normale Kamera bewegen,

967
02:16:02,320 --> 02:16:06,320
bewegen Sie Ihren Kopf,

968
02:16:07,320 --> 02:16:11,320
und wir können dann sowohl algorithmisch als auch im Kopf eine 3D-Erfassung der Szene machen.

969
02:16:12,320 --> 02:16:16,320
Man kann das auch mit Röntgenkameras machen.

970
02:16:17,320 --> 02:16:21,320
Sie können diese Apparatur, hier Beleuchtungsquelle, hier Sensor,

971
02:16:22,320 --> 02:16:26,320
um das Objekt herum drehen,

972
02:16:27,320 --> 02:16:31,320
hier haben wir das Bild dazu.

973
02:16:32,320 --> 02:16:36,320
Was wir als Mensch machen,

974
02:16:37,320 --> 02:16:41,320
wir machen eine Entfernungsschätzung.

975
02:16:42,320 --> 02:16:46,320
Wir haben zwei Kameras, linkses Auge und rechtes Auge,

976
02:16:47,320 --> 02:16:51,320
und wir fixieren einen Punkt.

977
02:16:52,320 --> 02:16:56,320
Wir wissen dann, wo dieser Punkt auf unserem Sensor ist,

978
02:16:57,320 --> 02:17:01,320
welchen Abstand dieser Punkt hat.

979
02:17:02,320 --> 02:17:06,320
Da kommt jetzt keine Zahl in Metern raus,

980
02:17:07,320 --> 02:17:11,320
das ist dann vielleicht ein nachrangiger Schätzprozess.

981
02:17:12,320 --> 02:17:16,320
Aber wir kriegen ein Gefühl dafür, wie weit weg ist das,

982
02:17:17,320 --> 02:17:21,320
wie viele Schritte müssen wir machen, um da hinzukommen.

983
02:17:22,320 --> 02:17:26,320
Das können wir mit Bildern auch machen.

984
02:17:27,320 --> 02:17:31,320
Das Paritätsbild, das wird berechnet aus zwei Bildern,

985
02:17:32,320 --> 02:17:36,320
gibt dann pro Bildpunkt an, wie weit entfernt ist es von der Kamera.

986
02:17:37,320 --> 02:17:41,320
Schauen wir uns hier einmal diesen Punkt an.

987
02:17:42,320 --> 02:17:46,320
Er ist an dieser Stelle in diesem Bild, an dieser Stelle in dem anderen Bild.

988
02:17:47,320 --> 02:17:51,320
Wenn dieser Punkt hier wäre,

989
02:17:52,320 --> 02:17:56,320
würde er sich in beiden Bildern bewegen.

990
02:17:57,320 --> 02:18:01,320
Er würde weiter dort sein, und hier würde er auch weiter nach außen gehen.

991
02:18:02,320 --> 02:18:06,320
Die Disparität würde größer werden, und daraus schließen wir dann,

992
02:18:07,320 --> 02:18:11,320
das Objekt ist näher dran.

993
02:18:12,320 --> 02:18:16,320
Wenn wir jetzt eine Disparitätskarte haben wollen,

994
02:18:17,320 --> 02:18:21,320
dann könnte die farbcodiert sein.

995
02:18:22,320 --> 02:18:26,320
Hier oben ein Bild von der Szene,

996
02:18:27,320 --> 02:18:31,320
und hier eine Verschiebung von dem Bildpunkt

997
02:18:32,320 --> 02:18:36,320
zu dem Bildpunkt in diesem Bild.

998
02:18:37,320 --> 02:18:41,320
Diese Bildkoordinate ist hier auch noch mal eingezeichnet.

999
02:18:42,320 --> 02:18:46,320
Der Ortsunterschied, das ist die Disparität.

1000
02:18:47,320 --> 02:18:51,320
Diese Größe der Disparität ist jetzt umgesetzt in Farbe,

1001
02:18:52,320 --> 02:18:56,320
und dann hier im Bild dargestellt.

1002
02:18:57,320 --> 02:19:01,320
Die Linien zum Sensor sind alle gleich weit entfernt.

1003
02:19:02,320 --> 02:19:06,320
Die Ampeln stehen ja vor.

1004
02:19:07,320 --> 02:19:11,320
Das ist also das hier.

1005
02:19:12,320 --> 02:19:16,320
Hier haben wir noch eine Ampel, die ist anscheinend ein bisschen weiter weg.

1006
02:19:17,320 --> 02:19:21,320
Sie sehen auch, in dieser Disparitätskarte sind diese Bäume hier anscheinend

1007
02:19:22,320 --> 02:19:26,320
nicht mehr vom Himmel unterschieden.

1008
02:19:27,320 --> 02:19:31,320
Das heißt, dass man diese Karte nicht mehr auflösen kann.

1009
02:19:32,320 --> 02:19:36,320
Dieses Schild hier vor dem Auto, das ist dann noch zu sehen.

1010
02:19:37,320 --> 02:19:41,320
Bei Disparitäten, das sehen Sie auch, wenn Sie gedanklich

1011
02:19:42,320 --> 02:19:46,320
diesen Punkt näher ranholen oder weiter wegschieben.

1012
02:19:47,320 --> 02:19:51,320
Je näher ran er kommt, desto größer

1013
02:19:52,320 --> 02:19:56,320
wandert der Punkt in die Richtung und der in die.

1014
02:19:57,320 --> 02:20:01,320
Dann wird die Disparität größer.

1015
02:20:02,320 --> 02:20:06,320
Und zwar relativ schnell.

1016
02:20:07,320 --> 02:20:11,320
Wenn der Punkt sich um die gleiche Entfernung

1017
02:20:12,320 --> 02:20:16,320
in die Richtung bewegt,

1018
02:20:17,320 --> 02:20:21,320
wird die Veränderung hier im Bild viel kleiner sein.

1019
02:20:22,320 --> 02:20:26,320
Mit Hilfe dieser Disparität können wir im Nahen

1020
02:20:27,320 --> 02:20:31,320
gut abschätzen, in der Ferne nicht.

1021
02:20:32,320 --> 02:20:36,320
Wenn ich aus dem Fenster gucke, weiß ich aufgrund meiner Erfahrung,

1022
02:20:37,320 --> 02:20:41,320
der Fernsehturm ist weiter weg als der Schornstein von Conti.

1023
02:20:42,320 --> 02:20:46,320
Aber das ist auch nur, weil ich ein Gefühl dafür habe,

1024
02:20:47,320 --> 02:20:51,320
was für ein Durchmesser so ein großer Schornstein hat und wie groß

1025
02:20:52,320 --> 02:20:56,320
der Telemax ist.

1026
02:20:57,320 --> 02:21:01,320
Je weiter weg Sie kommen, desto kleiner werden die Unterschiede.

1027
02:21:02,320 --> 02:21:06,320
Die Verschiebung zwischen dem linken und rechten Bild.

1028
02:21:07,320 --> 02:21:11,320
Der Vorteil bei der Messung mit Kameras ist, Sie wissen typischerweise,

1029
02:21:12,320 --> 02:21:16,320
was Sie wollen und können Ihre Kameras an Ihren Anwendungsfall anpassen.

1030
02:21:17,320 --> 02:21:21,320
Wenn Sie sich aber dafür interessieren, wie weit ist der Telemax weg

1031
02:21:22,320 --> 02:21:26,320
und wie weit ist der Schornstein von Conti weg, können Sie

1032
02:21:27,320 --> 02:21:31,320
die Unterschiede wieder messen.

1033
02:21:32,320 --> 02:21:36,320
Das kann ich mit meinen menschlichen Augen nicht machen.

1034
02:21:37,320 --> 02:21:41,320
Sie können so ein Distanzbild,

1035
02:21:42,320 --> 02:21:46,320
letztendlich dieses Disparitätsbild ist auch irgendwo ein Distanzbild.

1036
02:21:47,320 --> 02:21:51,320
Dieses Bild hier ist nicht skaliert in Metern, sondern in Disparität.

1037
02:21:52,320 --> 02:21:56,320
Aber Sie könnten das genauso gut in Abstand in Metern skalieren.

1038
02:21:57,320 --> 02:22:01,320
Sie können

1039
02:22:02,320 --> 02:22:06,320
neben Ihrer Kamera

1040
02:22:07,320 --> 02:22:11,320
eine Lampe einbauen, die projiziert ein Gitternetz.

1041
02:22:12,320 --> 02:22:16,320
Ein quadratisches Gitternetz zum Beispiel in die Szene.

1042
02:22:17,320 --> 02:22:21,320
Da hätten Sie hier jetzt letztendlich ein Gitternetz drauf

1043
02:22:22,320 --> 02:22:26,320
und bei Objekten, die nicht dran sind, sind diese Quadrate klein.

1044
02:22:27,320 --> 02:22:31,320
Und wenn Sie weiter wechseln, sind diese Quadrate dann offensichtlich groß.

1045
02:22:32,320 --> 02:22:36,320
Und mit diesem Wissen oder mit dieser Beobachtung

1046
02:22:37,320 --> 02:22:41,320
– ah, hier ist ein kleines Quadrat, hier ist ein großes Quadrat –

1047
02:22:42,320 --> 02:22:46,320
und Kenntnissen über die Optik Ihres Systems und des Gitternetzes,

1048
02:22:47,320 --> 02:22:51,320
was Sie projizieren, können Sie dann auf den Quadrat schließen.

1049
02:22:52,320 --> 02:22:56,320
Und so ist das etwas, was zum Beispiel die Microsoft Connect machen.

1050
02:22:57,320 --> 02:23:01,320
Dann haben Sie wahrscheinlich das Gittermuster nie gesehen.

1051
02:23:02,320 --> 02:23:06,320
Das liegt einfach daran, dass das in einem Frequenzbereich ausgestrahlt wird,

1052
02:23:07,320 --> 02:23:11,320
den wir nicht sehen können, der aber von der Kamera erfasst werden kann.

1053
02:23:12,320 --> 02:23:16,320
Es gibt

1054
02:23:17,320 --> 02:23:21,320
andere Sensoren, die auch Bilder erzeugen,

1055
02:23:22,320 --> 02:23:26,320
Tiefenbilder. Da ist dann der Wert eines Bildpunktes

1056
02:23:27,320 --> 02:23:31,320
– das sind nicht irgendwelche Helligkeiten, sondern ein Abstand.

1057
02:23:32,320 --> 02:23:36,320
Und dann gibt es die Time-of-Flight-Sensoren.

1058
02:23:37,320 --> 02:23:41,320
Das sind auch wieder aktive Sensoren, genauso wie ein Radarsensor.

1059
02:23:42,320 --> 02:23:46,320
Der ist aktiv, er strahlt Licht aus und misst, was er empfängt.

1060
02:23:47,320 --> 02:23:51,320
Die Microsoft Connect ist letztendlich auch ein aktiver Sensor.

1061
02:23:52,320 --> 02:23:56,320
Sie strahlt Licht aus und sammelt das Licht, was sie ausgestrahlt hat, Teile davon wieder ein.

1062
02:23:57,320 --> 02:24:01,320
Da ist auch dieser Time-of-Flight-Sensor ein aktiver Sensor.

1063
02:24:02,320 --> 02:24:06,320
Sie haben letztendlich hier einen Emitter, eine Beleuchtung, wenn Sie so wollen.

1064
02:24:07,320 --> 02:24:11,320
Die sendet aus ein modelliertes Lichtsignal.

1065
02:24:12,320 --> 02:24:16,320
Das wird dann irgendwann auf ein Objekt treffen.

1066
02:24:17,320 --> 02:24:21,320
Es kommt wieder zurück.

1067
02:24:22,320 --> 02:24:26,320
Sie fangen das auf und dann machen Sie eine

1068
02:24:27,320 --> 02:24:31,320
Veränderung zwischen dem, was Sie ausgesendet haben, und dem, was Sie empfangen.

1069
02:24:32,320 --> 02:24:36,320
Aus der Phasenverschiebung kriegen Sie dann letztendlich die Entfernung raus.

1070
02:24:37,320 --> 02:24:41,320
Die Phase ist ja nichts anderes als Zeit.

1071
02:24:42,320 --> 02:24:46,320
Zeit können Sie mit Lichtgeschwindigkeit in Strecke umrechnen.

1072
02:24:47,320 --> 02:24:51,320
Die Hälfte der Strecke ist dann das, was der Abstand zwischen dem Objekt und Ihrem Detektor ist.

1073
02:24:52,320 --> 02:24:56,320
Hier sehen Sie eine neue Kamera.

1074
02:24:57,320 --> 02:25:01,320
Damit können Sie hochgenau Abstand messen.

1075
02:25:02,320 --> 02:25:06,320
Die Genauigkeit, mit der Sie messen können,

1076
02:25:07,320 --> 02:25:11,320
hängt dann letztendlich von der Frequenz Ihres modellierten Signals ab.

1077
02:25:12,320 --> 02:25:16,320
Also nicht von der Frequenz des Lichtsignals selbst,

1078
02:25:17,320 --> 02:25:21,320
sondern von der Frequenz des modellierten Signals.

1079
02:25:22,320 --> 02:25:26,320
Damit können Sie letztendlich so eine Kamera ganz leicht für den speziellen Objekt messen.

1080
02:25:27,320 --> 02:25:31,320
Sie müssen nicht, wie bei der Disparitätsschätzung,

1081
02:25:32,320 --> 02:25:36,320
die Kameras hin und her bewegen.

1082
02:25:37,320 --> 02:25:41,320
Weitere bildgebende Verfahren im Bereich der Medizin.

1083
02:25:42,320 --> 02:25:46,320
Ultraschall ist auch ein aktives Verfahren.

1084
02:25:47,320 --> 02:25:51,320
Sie haben eine Ultraschall-Signalquelle im Kopf,

1085
02:25:52,320 --> 02:25:56,320
mit der man mit dem Menschen geht.

1086
02:25:57,320 --> 02:26:01,320
Die Ultraschall-Signalquelle erzeugt und die Schwingungen,

1087
02:26:02,320 --> 02:26:06,320
die sich dadurch verändern, können Sie nutzen,

1088
02:26:07,320 --> 02:26:11,320
um herauszufinden, was für ein Gewebe es sich da handelt.

1089
02:26:12,320 --> 02:26:16,320
Sie können auch radioaktive Substanzen in den Menschen einbringen

1090
02:26:17,320 --> 02:26:21,320
und dann gucken, wie sie sich im Körper verteilen,

1091
02:26:22,320 --> 02:26:26,320
wo sie sich ansammeln.

1092
02:26:27,320 --> 02:26:31,320
Da gibt es eine Vorlesung,

1093
02:26:32,320 --> 02:26:36,320
bildgebende Systeme in der Medizintechnik,

1094
02:26:37,320 --> 02:26:41,320
wenn Sie die verschiedenen Methoden näher interessieren.

1095
02:26:42,320 --> 02:26:46,320
Jetzt haben wir viele Beispiele gesehen,

1096
02:26:47,320 --> 02:26:51,320
was man mit Bildern machen kann.

1097
02:26:52,320 --> 02:26:56,320
Zusammengefasst, was kann man darstellen?

1098
02:26:57,320 --> 02:27:01,320
Das wäre ein Grauwert.

1099
02:27:02,320 --> 02:27:06,320
Es können Farben sein.

1100
02:27:07,320 --> 02:27:11,320
Es können aber auch Signale sein, die außerhalb des menschlichen Sichtbereichs sind.

1101
02:27:12,320 --> 02:27:16,320
Wir können ein Rotbild aufnehmen, ein Röntgenbild.

1102
02:27:17,320 --> 02:27:21,320
Wir können elektromagnetische Signale außerhalb des menschlichen Sichtbereichs visualisieren.

1103
02:27:22,320 --> 02:27:26,320
Das wären alles Intensitätswerte.

1104
02:27:27,320 --> 02:27:31,320
Wir hatten da die Tiefenkarten, Distanzen.

1105
02:27:32,320 --> 02:27:36,320
Wenn wir an Röntgenbilder denken, kann man auch sagen, wir stellen dar,

1106
02:27:37,320 --> 02:27:41,320
die Durchstrahlung von Körpern.

1107
02:27:42,320 --> 02:27:46,320
Sie können die Konzentration von Gasen, von Schadstoffen darstellen.

1108
02:27:47,320 --> 02:27:51,320
Sie können auch Bedeutungen darstellen.

1109
02:27:52,320 --> 02:27:56,320
Sie könnten ein Bild segmentieren in verschiedene topografische Eigenschaften,

1110
02:27:57,320 --> 02:28:01,320
z.B. in Wald, Ebenen,

1111
02:28:02,320 --> 02:28:06,320
Oberflächen, Siedlungszonen, Industriegebiete,

1112
02:28:07,320 --> 02:28:11,320
Ackerflächen, Waldflächen.

1113
02:28:12,320 --> 02:28:16,320
Es gibt also viele Dinge, die Sie auf Bilder abbilden können.

1114
02:28:17,320 --> 02:28:21,320
Wenn Sie eine zweidimensionale Darstellung von Informationen haben wollen,

1115
02:28:22,320 --> 02:28:26,320
können Sie das mit Bildern typischerweise repräsentieren.

1116
02:28:27,320 --> 02:28:31,320
Der typische Sensor, den wir heute gesehen haben, war der Flächensensor.

1117
02:28:32,320 --> 02:28:36,320
Der ist zweidimensional.

1118
02:28:37,320 --> 02:28:41,320
Der typische Sensor hat die Möglichkeit, Farbe aufzunehmen.

1119
02:28:42,320 --> 02:28:46,320
Entweder weil ich vor benachbarten Bildpunkten unterschiedliche Farbfilter habe.

1120
02:28:47,320 --> 02:28:51,320
Das ist dann eine Kamera mit einem Sensor.

1121
02:28:52,320 --> 02:28:56,320
Oder weil ich eine etwas teurere Anordnung habe, wo ich das Licht erst durch ein Prisma schicke.

1122
02:28:57,320 --> 02:29:01,320
Da habe ich also einen Farbsensor.

1123
02:29:02,320 --> 02:29:06,320
Neben diesem Flächensensor gibt es auch den Zeilensensor, der immer dann von Interesse ist,

1124
02:29:07,320 --> 02:29:11,320
wenn das, was ich aufnehmen will, sich bewegt.

1125
02:29:12,320 --> 02:29:16,320
Beobachte Teile auf einem Förderband z.B.

1126
02:29:17,320 --> 02:29:21,320
Oder der Sensor bewegt sich, wenn ich fliege mit meinem Flugzeug über die Bundesrepublik

1127
02:29:22,320 --> 02:29:26,320
oder der Satellit umkreist die Erde.

1128
02:29:27,320 --> 02:29:31,320
Das ist klar.

1129
02:29:32,320 --> 02:29:36,320
Wir können verschiedene physikalische und semantische Größen

1130
02:29:37,320 --> 02:29:41,320
durch digitale Bilder repräsentieren.

1131
02:29:42,320 --> 02:29:46,320
Abhängig davon, was unsere Sensoren machen

1132
02:29:47,320 --> 02:29:51,320
und auch abhängig davon, was wir schon berechnet haben.

1133
02:29:52,320 --> 02:29:56,320
Distanzbilder z.B. kann man berechnen.

1134
02:29:57,320 --> 02:30:01,320
Die Distanz ausgerechnet.

1135
02:30:02,320 --> 02:30:06,320
Gut.

1136
02:30:07,320 --> 02:30:11,320
An dieser Stelle höre ich für heute auf.

1137
02:30:12,320 --> 02:30:16,320
Ich wünsche Ihnen eine schöne Woche und bis zum nächsten Mal.

